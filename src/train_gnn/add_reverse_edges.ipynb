{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "heterodata = pickle.load(open(\"hetero_graph_final.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    license=[1000],\n",
       "    doi=[1000],\n",
       "    pages=[1000],\n",
       "    journal=[1000],\n",
       "    date=[1000],\n",
       "    id=[1000],\n",
       "    name=[1000],\n",
       "    num_nodes=1000,\n",
       "  },\n",
       "  author={\n",
       "    name=[2886],\n",
       "    num_nodes=2886,\n",
       "  },\n",
       "  category={\n",
       "    name=[108],\n",
       "    num_nodes=108,\n",
       "  },\n",
       "  word={\n",
       "    name=[10667],\n",
       "    num_nodes=10667,\n",
       "  },\n",
       "  journal={\n",
       "    name=[574],\n",
       "    num_nodes=574,\n",
       "  },\n",
       "  (paper, written_by, author)={ edge_index=[2, 3068] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 1502] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 77703],\n",
       "    edge_attr=[77703],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 7462] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 1000] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 499132],\n",
       "    edge_attr=[499132],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterodata['paper']['license'] = [license if license is not None else 'None' for license in heterodata['paper']['license']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 336\n",
    "# idx2 = 4\n",
    "# a= heterodata[heterodata.edge_types[idx2]].edge_index\n",
    "# from_node = heterodata[heterodata.edge_types[idx2][0]].name[a[0,idx]]\n",
    "# to_node = heterodata[heterodata.edge_types[idx2][2]].name[a[1,idx]]\n",
    "\n",
    "# print(heterodata.edge_types[idx2][0], from_node)\n",
    "# print(heterodata.edge_types[idx2][2], to_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heterodata[('paper', 'in_journal', 'journal')] = heterodata[('paper', 'in_journal', 'journal-ref')]\n",
    "# del heterodata[('paper', 'in_journal', 'journal-ref')]\n",
    "\n",
    "# remove isolated nodes\n",
    "import torch_geometric.transforms as T\n",
    "transform = T.Compose([\n",
    "       #T.RemoveIsolatedNodes(),\n",
    "       T.RemoveDuplicatedEdges(),\n",
    "       # T.ToUndirected(merge=False) # don't merge reversed edges into the original edge type\n",
    "])\n",
    "from torch_geometric.data import HeteroData \n",
    "\n",
    "# from copy import deepcopy\n",
    "# data = deepcopy(heterodata)\n",
    "# for node_type in heterodata.node_types[-5:]:\n",
    "       # heterodata[node_type].num_nodes = hetero\n",
    "\n",
    "# for edge_type in  heterodata.edge_types[-:]:\n",
    "       # print(edge_type)\n",
    "       # \n",
    "       # del data[edge_type]\n",
    "       # del data[list(reversed(heterodata.edge_types))[5]]\n",
    "\n",
    "# for node_type in heterodata.node_types[:6]:\n",
    "#        print(node_type)\n",
    "#        del data[node_type]\n",
    "# test = transform(data)\n",
    "heterodata = transform(heterodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n",
      "del paper license\n",
      "del paper doi\n",
      "del paper pages\n",
      "del paper journal\n",
      "del paper date\n",
      "del paper id\n",
      "del paper name\n",
      "del paper num_nodes\n",
      "author\n",
      "del author name\n",
      "del author num_nodes\n",
      "category\n",
      "del category name\n",
      "del category num_nodes\n",
      "word\n",
      "del word name\n",
      "del word num_nodes\n",
      "journal\n",
      "del journal name\n",
      "del journal num_nodes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# id mapping so we can remove the attributes and then remove isolated nodes, later we can add the attributes back\n",
    "id_dict = {}\n",
    "heterodata_dict = heterodata.to_dict()\n",
    "for nodetype in heterodata.node_types:\n",
    "    print(nodetype)\n",
    "    ids = torch.arange(heterodata[nodetype].num_nodes) \n",
    "    id_mapping = {i.item():name for i, name in zip(ids, heterodata[nodetype].name)}\n",
    "    \n",
    "    heterodata[nodetype].x = ids.squeeze(-1)\n",
    "    id_dict[nodetype] = id_mapping\n",
    "    \n",
    "    for key in heterodata_dict[nodetype].keys():\n",
    "        if key != 'x':\n",
    "            print('del', nodetype, key)\n",
    "            del heterodata[nodetype][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={ x=[1000] },\n",
       "  author={ x=[2886] },\n",
       "  category={ x=[108] },\n",
       "  word={ x=[10667] },\n",
       "  journal={ x=[574] },\n",
       "  (paper, written_by, author)={ edge_index=[2, 3067] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 1502] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 57073],\n",
       "    edge_attr=[57073],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 7354] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 1000] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 499132],\n",
       "    edge_attr=[499132],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correct edge types:\n",
    "transform = T.Compose([\n",
    "       T.RemoveIsolatedNodes(),\n",
    "       #    T.RemoveDuplicatedEdges(),\n",
    "       # T.ToUndirected(merge=False) # don't merge reversed edges into the original edge type\n",
    "])\n",
    "\n",
    "heterodata = transform(heterodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={ x=[1000] },\n",
       "  author={ x=[2886] },\n",
       "  category={ x=[108] },\n",
       "  word={ x=[10604] },\n",
       "  journal={ x=[574] },\n",
       "  (paper, written_by, author)={ edge_index=[2, 3067] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 1502] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 57073],\n",
       "    edge_attr=[57073],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 7354] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 1000] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 499132],\n",
       "    edge_attr=[499132],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterodata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import json \n",
    "# import pandas as pd \n",
    "\n",
    "# def read_first_n_lines(file_path, n=10000):\n",
    "#     data = []\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for i, line in tqdm(enumerate(file), total=n):\n",
    "#             if i >= n:\n",
    "#                 break\n",
    "#             try:\n",
    "#                 data.append(json.loads(line))\n",
    "#             except json.JSONDecodeError:\n",
    "#                 continue\n",
    "#     return pd.DataFrame(data)\n",
    "\n",
    "# file_path = '../make_the_graph/data/arxiv-metadata-oai-snapshot.json'\n",
    "\n",
    "# # DataFrame erstellen\n",
    "# df = read_first_n_lines(file_path, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterodata = T.ToUndirected()(heterodata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n",
      "author\n",
      "category\n",
      "word\n",
      "journal\n"
     ]
    }
   ],
   "source": [
    "# map back\n",
    "for nodetype in heterodata.node_types:\n",
    "    print(nodetype)\n",
    "    id_mapping = id_dict[nodetype]\n",
    "    heterodata[nodetype].name = [id_mapping[i.item()] for i in heterodata[nodetype].x]\n",
    "    del heterodata[nodetype].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 330\n",
    "# idx2 = 4\n",
    "# a= heterodata[heterodata.edge_types[idx2]].edge_index\n",
    "# from_node = heterodata[heterodata.edge_types[idx2][0]].name[a[0,idx]]\n",
    "# to_node = heterodata[heterodata.edge_types[idx2][2]].name[a[1,idx]]\n",
    "\n",
    "# print(heterodata.edge_types[idx2][0], from_node)\n",
    "# print(heterodata.edge_types[idx2][2], to_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={ name=[1000] },\n",
       "  author={ name=[2886] },\n",
       "  category={ name=[108] },\n",
       "  word={ name=[10604] },\n",
       "  journal={ name=[574] },\n",
       "  (paper, written_by, author)={ edge_index=[2, 3067] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 1502] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 57073],\n",
       "    edge_attr=[57073],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 7354] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 1000] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 871906],\n",
       "    edge_attr=[871906],\n",
       "  },\n",
       "  (author, rev_written_by, paper)={ edge_index=[2, 3067] },\n",
       "  (category, rev_has_category, paper)={ edge_index=[2, 1502] },\n",
       "  (word, rev_has_word, paper)={\n",
       "    edge_index=[2, 57073],\n",
       "    edge_attr=[57073],\n",
       "  },\n",
       "  (word, rev_has_titleword, paper)={ edge_index=[2, 7354] },\n",
       "  (journal, rev_in_journal, paper)={ edge_index=[2, 1000] }\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for training\n",
    "import pickle\n",
    "pickle.dump(heterodata, open(\"arxiv_author_paper_graph_no_features.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nodetype in heterodata.node_types:\n",
    "#     print(nodetype, heterodata[nodetype].x.shape, heterodata[nodetype].num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "author\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "category\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "word\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "journal\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "('paper', 'written_by', 'author')\n",
      "   3067\n",
      "   {'edge_index': tensor([[   0,    0,    0,  ...,  997,  998,  999],\n",
      "        [   0,    1,    2,  ..., 2883, 2884, 2885]])}\n",
      "('paper', 'has_category', 'category')\n",
      "   1502\n",
      "   {'edge_index': tensor([[  0,   1,   1,  ..., 997, 998, 999],\n",
      "        [  0,   1,   2,  ...,  10,  52,  15]])}\n",
      "('paper', 'has_word', 'word')\n",
      "   57073\n",
      "   {'edge_index': tensor([[    0,     0,     0,  ...,   999,   999,   999],\n",
      "        [    0,     1,     2,  ..., 10209, 10210, 10211]]), 'edge_attr': tensor([0.0942, 0.0789, 0.2729,  ..., 0.1235, 0.1235, 0.1235])}\n",
      "('paper', 'has_titleword', 'word')\n",
      "   7354\n",
      "   {'edge_index': tensor([[    0,     0,     0,  ...,   999,   999,   999],\n",
      "        [    2,     7,    41,  ..., 10191, 10192, 10193]])}\n",
      "('paper', 'in_journal', 'journal')\n",
      "   1000\n",
      "   {'edge_index': tensor([[  0,   1,   2,  ..., 997, 998, 999],\n",
      "        [  0,   1,   1,  ...,   1,   1, 573]])}\n",
      "('word', 'co_occurs_with', 'word')\n",
      "   871906\n",
      "   {'edge_index': tensor([[    0,     0,     0,  ..., 10211, 10211, 10211],\n",
      "        [    1,     2,     3,  ..., 10208, 10209, 10210]]), 'edge_attr': tensor([0.2206, 0.1658, 0.3182,  ..., 0.8049, 0.8049, 0.8049])}\n",
      "('author', 'rev_written_by', 'paper')\n",
      "   3067\n",
      "   {'edge_index': tensor([[   0,    1,    2,  ..., 2883, 2884, 2885],\n",
      "        [   0,    0,    0,  ...,  997,  998,  999]])}\n",
      "('category', 'rev_has_category', 'paper')\n",
      "   1502\n",
      "   {'edge_index': tensor([[  0,   1,   2,  ...,  10,  52,  15],\n",
      "        [  0,   1,   1,  ..., 997, 998, 999]])}\n",
      "('word', 'rev_has_word', 'paper')\n",
      "   57073\n",
      "   {'edge_index': tensor([[    0,     1,     2,  ..., 10209, 10210, 10211],\n",
      "        [    0,     0,     0,  ...,   999,   999,   999]]), 'edge_attr': tensor([0.0942, 0.0789, 0.2729,  ..., 0.1235, 0.1235, 0.1235])}\n",
      "('word', 'rev_has_titleword', 'paper')\n",
      "   7354\n",
      "   {'edge_index': tensor([[    2,     7,    41,  ..., 10191, 10192, 10193],\n",
      "        [    0,     0,     0,  ...,   999,   999,   999]])}\n",
      "('journal', 'rev_in_journal', 'paper')\n",
      "   1000\n",
      "   {'edge_index': tensor([[  0,   1,   1,  ...,   1,   1, 573],\n",
      "        [  0,   1,   2,  ..., 997, 998, 999]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[paper]' to suppress this warning\n",
      "  warnings.warn(\n",
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[author]' to suppress this warning\n",
      "  warnings.warn(\n",
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[category]' to suppress this warning\n",
      "  warnings.warn(\n",
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[word]' to suppress this warning\n",
      "  warnings.warn(\n",
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[journal]' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def describe(heterodata):\n",
    "    heterodata_dict = heterodata.to_dict()\n",
    "    # print('has isolated nodes:', heterodata.has_isolated_nodes())\n",
    "    # print('has self loops:', heterodata.has_self_loops())\n",
    "    # print('is directed', heterodata.is_directed())\n",
    "    for nodetype in heterodata.node_types:\n",
    "        print(nodetype)\n",
    "        print('  ',heterodata[nodetype].num_nodes)\n",
    "        print('  ',heterodata_dict[nodetype].keys())\n",
    "        \n",
    "    for edgetype in heterodata.edge_types:\n",
    "        print(edgetype)\n",
    "        print('  ',heterodata[edgetype].num_edges)\n",
    "        print('  ',heterodata[edgetype])\n",
    "\n",
    "# describe(heterodata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
