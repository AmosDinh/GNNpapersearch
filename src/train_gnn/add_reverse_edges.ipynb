{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "heterodata = pickle.load(open(\"hetero_graph_final.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    license=[2381173],\n",
       "    doi=[2381173],\n",
       "    pages=[2381173],\n",
       "    journal=[2381173],\n",
       "    date=[2381173],\n",
       "    id=[2381173],\n",
       "    name=[2381173],\n",
       "    num_nodes=2381173,\n",
       "  },\n",
       "  author={\n",
       "    name=[1894426],\n",
       "    num_nodes=1894426,\n",
       "  },\n",
       "  category={\n",
       "    name=[176],\n",
       "    num_nodes=176,\n",
       "  },\n",
       "  word={\n",
       "    name=[2465063],\n",
       "    num_nodes=2465063,\n",
       "  },\n",
       "  journal={\n",
       "    name=[815904],\n",
       "    num_nodes=815904,\n",
       "  },\n",
       "  (paper, written_by, author)={ edge_index=[2, 10595660] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 4035894] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 217335585],\n",
       "    edge_attr=[217335585],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 18672617] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 2381173] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 160852251],\n",
       "    edge_attr=[160852251],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterodata['paper']['license'] = [license if license is not None else 'None' for license in heterodata['paper']['license']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 336\n",
    "# idx2 = 4\n",
    "# a= heterodata[heterodata.edge_types[idx2]].edge_index\n",
    "# from_node = heterodata[heterodata.edge_types[idx2][0]].name[a[0,idx]]\n",
    "# to_node = heterodata[heterodata.edge_types[idx2][2]].name[a[1,idx]]\n",
    "\n",
    "# print(heterodata.edge_types[idx2][0], from_node)\n",
    "# print(heterodata.edge_types[idx2][2], to_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heterodata[('paper', 'in_journal', 'journal')] = heterodata[('paper', 'in_journal', 'journal-ref')]\n",
    "# del heterodata[('paper', 'in_journal', 'journal-ref')]\n",
    "\n",
    "# remove isolated nodes\n",
    "import torch_geometric.transforms as T\n",
    "transform = T.Compose([\n",
    "       #T.RemoveIsolatedNodes(),\n",
    "       T.RemoveDuplicatedEdges(),\n",
    "       # T.ToUndirected(merge=False) # don't merge reversed edges into the original edge type\n",
    "])\n",
    "from torch_geometric.data import HeteroData \n",
    "\n",
    "# from copy import deepcopy\n",
    "# data = deepcopy(heterodata)\n",
    "# for node_type in heterodata.node_types[-5:]:\n",
    "       # heterodata[node_type].num_nodes = hetero\n",
    "\n",
    "# for edge_type in  heterodata.edge_types[-:]:\n",
    "       # print(edge_type)\n",
    "       # \n",
    "       # del data[edge_type]\n",
    "       # del data[list(reversed(heterodata.edge_types))[5]]\n",
    "\n",
    "# for node_type in heterodata.node_types[:6]:\n",
    "#        print(node_type)\n",
    "#        del data[node_type]\n",
    "# test = transform(data)\n",
    "heterodata = transform(heterodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n",
      "del paper license\n",
      "del paper doi\n",
      "del paper pages\n",
      "del paper journal\n",
      "del paper date\n",
      "del paper id\n",
      "del paper name\n",
      "del paper num_nodes\n",
      "author\n",
      "del author name\n",
      "del author num_nodes\n",
      "category\n",
      "del category name\n",
      "del category num_nodes\n",
      "word\n",
      "del word name\n",
      "del word num_nodes\n",
      "journal\n",
      "del journal name\n",
      "del journal num_nodes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# id mapping so we can remove the attributes and then remove isolated nodes, later we can add the attributes back\n",
    "id_dict = {}\n",
    "more_mappings = {}\n",
    "heterodata_dict = heterodata.to_dict()\n",
    "for nodetype in heterodata.node_types:\n",
    "    print(nodetype)\n",
    "    ids = torch.arange(heterodata[nodetype].num_nodes) \n",
    "    id_mapping = {i.item():name for i, name in zip(ids, heterodata[nodetype].name)}\n",
    "    if nodetype =='paper':\n",
    "        for key in ['license','doi','pages','journal','date','id']:\n",
    "            more_mappings[key] = {i.item():name for i, name in zip(ids, heterodata[nodetype][key])}\n",
    "    \n",
    "    heterodata[nodetype].x = ids.squeeze(-1)\n",
    "    id_dict[nodetype] = id_mapping\n",
    "    \n",
    "    for key in heterodata_dict[nodetype].keys():\n",
    "        if key != 'x':\n",
    "            print('del', nodetype, key)\n",
    "            del heterodata[nodetype][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={ x=[2381173] },\n",
       "  author={ x=[1894426] },\n",
       "  category={ x=[176] },\n",
       "  word={ x=[2465063] },\n",
       "  journal={ x=[815904] },\n",
       "  (paper, written_by, author)={ edge_index=[2, 10586478] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 4035894] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 156112429],\n",
       "    edge_attr=[156112429],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 18361007] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 2381173] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 160852251],\n",
       "    edge_attr=[160852251],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correct edge types:\n",
    "transform = T.Compose([\n",
    "       T.RemoveIsolatedNodes(),\n",
    "       #    T.RemoveDuplicatedEdges(),\n",
    "       # T.ToUndirected(merge=False) # don't merge reversed edges into the original edge type\n",
    "])\n",
    "\n",
    "heterodata = transform(heterodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={ x=[2381173] },\n",
       "  author={ x=[1894426] },\n",
       "  category={ x=[176] },\n",
       "  word={ x=[2464870] },\n",
       "  journal={ x=[815904] },\n",
       "  (paper, written_by, author)={ edge_index=[2, 10586478] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 4035894] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 156112429],\n",
       "    edge_attr=[156112429],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 18361007] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 2381173] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 160852251],\n",
       "    edge_attr=[160852251],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterodata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import json \n",
    "# import pandas as pd \n",
    "\n",
    "# def read_first_n_lines(file_path, n=10000):\n",
    "#     data = []\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for i, line in tqdm(enumerate(file), total=n):\n",
    "#             if i >= n:\n",
    "#                 break\n",
    "#             try:\n",
    "#                 data.append(json.loads(line))\n",
    "#             except json.JSONDecodeError:\n",
    "#                 continue\n",
    "#     return pd.DataFrame(data)\n",
    "\n",
    "# file_path = '../make_the_graph/data/arxiv-metadata-oai-snapshot.json'\n",
    "\n",
    "# # DataFrame erstellen\n",
    "# df = read_first_n_lines(file_path, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterodata = T.ToUndirected()(heterodata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n",
      "author\n",
      "category\n",
      "word\n",
      "journal\n"
     ]
    }
   ],
   "source": [
    "# map back\n",
    "for nodetype in heterodata.node_types:\n",
    "    print(nodetype)\n",
    "    id_mapping = id_dict[nodetype]\n",
    "    heterodata[nodetype].name = [id_mapping[i.item()] for i in heterodata[nodetype].x]\n",
    "    \n",
    "    heterodata[nodetype].num_nodes = len(heterodata[nodetype].name)\n",
    "    \n",
    "    if nodetype =='paper':\n",
    "        for key in ['license','doi','pages','journal','date','id']:\n",
    "            heterodata[nodetype][key] = [more_mappings[key][i.item()] for i in heterodata[nodetype].x]\n",
    "    \n",
    "    del heterodata[nodetype].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 330\n",
    "# idx2 = 4\n",
    "# a= heterodata[heterodata.edge_types[idx2]].edge_index\n",
    "# from_node = heterodata[heterodata.edge_types[idx2][0]].name[a[0,idx]]\n",
    "# to_node = heterodata[heterodata.edge_types[idx2][2]].name[a[1,idx]]\n",
    "\n",
    "# print(heterodata.edge_types[idx2][0], from_node)\n",
    "# print(heterodata.edge_types[idx2][2], to_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "if not os.path.exists('arxiv_author_paper_graph_no_features_bare.pkl'):\n",
    "    pickle.dump(heterodata, open(\"arxiv_author_paper_graph_no_features_bare.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper nans to median\n",
    "import math\n",
    "non_nan = [num for num in heterodata['paper'].pages if not math.isnan(num)]\n",
    "median = non_nan[len(non_nan)//2]\n",
    "heterodata['paper'].pages = [median if math.isnan(num) else num for num in heterodata['paper'].pages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical \n",
    "unique_licenses= list(set(heterodata['paper'].license))\n",
    "categories = {unique_licenses[i]:i for i in range(len(unique_licenses))}\n",
    "heterodata['paper'].license = [categories[license] for license in heterodata['paper'].license]\n",
    "import torch \n",
    "# onehot\n",
    "onehot = torch.nn.functional.one_hot(torch.tensor(heterodata['paper'].license ))\n",
    "heterodata['paper'].license = onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_timestamp = heterodata['paper'].date[0]\n",
    "import datetime\n",
    "start_timestamp_epoch = datetime.datetime(1970, 1, 1, 0, 0, 0, tzinfo=given_timestamp.tzinfo)\n",
    "\n",
    "# Calculate the difference in hours divided by \n",
    "difference_in_hours_by_4 = (given_timestamp - start_timestamp_epoch).total_seconds() // (3600*4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterodata['paper'].date = [((timestamp - start_timestamp_epoch).total_seconds() // (3600*4)) for timestamp in heterodata['paper'].date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [1:01:52<00:00, 15.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [28:53<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 156/247 [26:09<16:07, 10.64s/it]"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# skill_sbert_embeddings = embedder.encode(skill_nodes['skill'].tolist(), convert_to_numpy=True)\n",
    "from tqdm.auto import tqdm\n",
    "# for each node type create the x attribute from the embeddings of the node names\n",
    "for node_type in heterodata.node_types:\n",
    "    print(node_type)\n",
    "    # do it in batches\n",
    "    x = torch.zeros(heterodata[node_type].num_nodes, 384).float()\n",
    "    batch_size = 10000\n",
    "    for i in tqdm(range(0, heterodata[node_type].num_nodes, 10000)):\n",
    "        x[i:i+10000] = torch.tensor(embedder.encode(heterodata[node_type].name[i:i+10000], convert_to_numpy=True))\n",
    "        \n",
    "        \n",
    "    heterodata[node_type].x = x\n",
    "    # heterodata[node_type].x = embedder.encode(heterodata[node_type].name, convert_to_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterodata['paper'].x = torch.concatenate((heterodata['paper'].x,heterodata['paper'].license), dim=1)\n",
    "heterodata['paper'].x  = torch.concatenate((heterodata['paper'].x, torch.tensor(heterodata['paper'].date).unsqueeze(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_type in heterodata.node_types:\n",
    "    del heterodata[node_type].name \n",
    "    if node_type == 'paper':\n",
    "        for key in ['license','doi','pages','journal','date','id']:\n",
    "            del heterodata[node_type][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "import pickle\n",
    "import os\n",
    "if not os.path.exists('arxiv_author_paper_graph_training.pkl'):\n",
    "    pickle.dump(heterodata, open(\"arxiv_author_paper_graph_training.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nodetype in heterodata.node_types:\n",
    "#     print(nodetype, heterodata[nodetype].x.shape, heterodata[nodetype].num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "author\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "category\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "word\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "journal\n",
      "   None\n",
      "   dict_keys(['name'])\n",
      "('paper', 'written_by', 'author')\n",
      "   3067\n",
      "   {'edge_index': tensor([[   0,    0,    0,  ...,  997,  998,  999],\n",
      "        [   0,    1,    2,  ..., 2883, 2884, 2885]])}\n",
      "('paper', 'has_category', 'category')\n",
      "   1502\n",
      "   {'edge_index': tensor([[  0,   1,   1,  ..., 997, 998, 999],\n",
      "        [  0,   1,   2,  ...,  10,  52,  15]])}\n",
      "('paper', 'has_word', 'word')\n",
      "   57073\n",
      "   {'edge_index': tensor([[    0,     0,     0,  ...,   999,   999,   999],\n",
      "        [    0,     1,     2,  ..., 10209, 10210, 10211]]), 'edge_attr': tensor([0.0942, 0.0789, 0.2729,  ..., 0.1235, 0.1235, 0.1235])}\n",
      "('paper', 'has_titleword', 'word')\n",
      "   7354\n",
      "   {'edge_index': tensor([[    0,     0,     0,  ...,   999,   999,   999],\n",
      "        [    2,     7,    41,  ..., 10191, 10192, 10193]])}\n",
      "('paper', 'in_journal', 'journal')\n",
      "   1000\n",
      "   {'edge_index': tensor([[  0,   1,   2,  ..., 997, 998, 999],\n",
      "        [  0,   1,   1,  ...,   1,   1, 573]])}\n",
      "('word', 'co_occurs_with', 'word')\n",
      "   871906\n",
      "   {'edge_index': tensor([[    0,     0,     0,  ..., 10211, 10211, 10211],\n",
      "        [    1,     2,     3,  ..., 10208, 10209, 10210]]), 'edge_attr': tensor([0.2206, 0.1658, 0.3182,  ..., 0.8049, 0.8049, 0.8049])}\n",
      "('author', 'rev_written_by', 'paper')\n",
      "   3067\n",
      "   {'edge_index': tensor([[   0,    1,    2,  ..., 2883, 2884, 2885],\n",
      "        [   0,    0,    0,  ...,  997,  998,  999]])}\n",
      "('category', 'rev_has_category', 'paper')\n",
      "   1502\n",
      "   {'edge_index': tensor([[  0,   1,   2,  ...,  10,  52,  15],\n",
      "        [  0,   1,   1,  ..., 997, 998, 999]])}\n",
      "('word', 'rev_has_word', 'paper')\n",
      "   57073\n",
      "   {'edge_index': tensor([[    0,     1,     2,  ..., 10209, 10210, 10211],\n",
      "        [    0,     0,     0,  ...,   999,   999,   999]]), 'edge_attr': tensor([0.0942, 0.0789, 0.2729,  ..., 0.1235, 0.1235, 0.1235])}\n",
      "('word', 'rev_has_titleword', 'paper')\n",
      "   7354\n",
      "   {'edge_index': tensor([[    2,     7,    41,  ..., 10191, 10192, 10193],\n",
      "        [    0,     0,     0,  ...,   999,   999,   999]])}\n",
      "('journal', 'rev_in_journal', 'paper')\n",
      "   1000\n",
      "   {'edge_index': tensor([[  0,   1,   1,  ...,   1,   1, 573],\n",
      "        [  0,   1,   2,  ..., 997, 998, 999]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[paper]' to suppress this warning\n",
      "  warnings.warn(\n",
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[author]' to suppress this warning\n",
      "  warnings.warn(\n",
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[category]' to suppress this warning\n",
      "  warnings.warn(\n",
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[word]' to suppress this warning\n",
      "  warnings.warn(\n",
      "/home/amosd/miniconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'name'}'. Please explicitly set 'num_nodes' as an attribute of 'data[journal]' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def describe(heterodata):\n",
    "    heterodata_dict = heterodata.to_dict()\n",
    "    # print('has isolated nodes:', heterodata.has_isolated_nodes())\n",
    "    # print('has self loops:', heterodata.has_self_loops())\n",
    "    # print('is directed', heterodata.is_directed())\n",
    "    for nodetype in heterodata.node_types:\n",
    "        print(nodetype)\n",
    "        print('  ',heterodata[nodetype].num_nodes)\n",
    "        print('  ',heterodata_dict[nodetype].keys())\n",
    "        \n",
    "    for edgetype in heterodata.edge_types:\n",
    "        print(edgetype)\n",
    "        print('  ',heterodata[edgetype].num_edges)\n",
    "        print('  ',heterodata[edgetype])\n",
    "\n",
    "# describe(heterodata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
