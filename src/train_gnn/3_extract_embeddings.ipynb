{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch==2.1.0  torchvision==0.16.0 torchtext==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "# #! pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html # torch_spline_conv\n",
    "# ! pip install torch_geometric\n",
    "# ! pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "# #! pip install torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "# #! pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "# #! pip install pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "# ! pip install sentence-transformers\n",
    "# ! pip install torcheval\n",
    "# ! pip install matplotlib\n",
    "# ! pip install pandas\n",
    "# ! pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load author.pt\n",
      "load author_rev_written_by_paper.pt\n",
      "load category.pt\n",
      "load category_rev_has_category_paper.pt\n",
      "load journal.pt\n",
      "load journal_rev_in_journal_paper.pt\n",
      "load paper.pt\n",
      "load paper_has_category_category.pt\n",
      "load paper_has_titleword_word.pt\n",
      "load paper_has_word_word.pt\n",
      "load paper_in_journal_journal.pt\n",
      "load paper_written_by_author.pt\n",
      "load word.pt\n",
      "load word_co_occurs_with_word.pt\n",
      "load word_rev_co_occurs_with_word.pt\n",
      "load word_rev_has_titleword_paper.pt\n",
      "load word_rev_has_word_paper.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from graph_sampler import get_datasets, equal_edgeweight_hgt_sampler, get_minibatch_count, add_reverse_edge_original_attributes_and_label_inplace, get_hgt_linkloader, get_single_minibatch_count, sampler_for_init\n",
    "import pickle \n",
    "import torch\n",
    "import os \n",
    "from torch_geometric.data import HeteroData\n",
    "def load_heterograph_dataset(folder):\n",
    "    dataset = HeteroData()\n",
    "    for name in os.listdir(folder):\n",
    "        print('load', name)\n",
    "        path = os.path.join(folder, name)\n",
    "        if os.path.isfile(path):\n",
    "            data = torch.load(path)\n",
    "            for key, value in data['attributes'].items():\n",
    "                dataset[data['name']][key] = value\n",
    "    return dataset\n",
    "\n",
    "data = load_heterograph_dataset('data_arxiv_paper')#pickle.load(open('/kaggle/input/arxiv-paper-graph/train_data_arxiv_paper.pkl', 'rb'))\n",
    "#val_data = pickle.load(open('/kaggle/input/arxiv-paper-graph/val_data_arxiv_paper.pkl', 'rb'))\n",
    "#test_data = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#train_data, val_data, test_data = get_datasets(get_edge_attr=False, filter_top_k=True, top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.kge import TransE\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.kge import KGEModel\n",
    "\n",
    "# adapted and taken from https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/nn/kge/transe.py\n",
    "\n",
    "class TransE(KGEModel):\n",
    "    r\"\"\"The TransE model from the `\"Translating Embeddings for Modeling\n",
    "    Multi-Relational Data\" <https://proceedings.neurips.cc/paper/2013/file/\n",
    "    1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf>`_ paper.\n",
    "\n",
    "    :class:`TransE` models relations as a translation from head to tail\n",
    "    entities such that\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{e}_h + \\mathbf{e}_r \\approx \\mathbf{e}_t,\n",
    "\n",
    "    resulting in the scoring function:\n",
    "\n",
    "    .. math::\n",
    "        d(h, r, t) = - {\\| \\mathbf{e}_h + \\mathbf{e}_r - \\mathbf{e}_t \\|}_p\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using the :class:`TransE` model, see\n",
    "        `examples/kge_fb15k_237.py\n",
    "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        kge_fb15k_237.py>`_.\n",
    "\n",
    "    Args:\n",
    "        num_nodes (int): The number of nodes/entities in the graph.\n",
    "        num_relations (int): The number of relations in the graph.\n",
    "        hidden_channels (int): The hidden embedding size.\n",
    "        margin (int, optional): The margin of the ranking loss.\n",
    "            (default: :obj:`1.0`)\n",
    "        p_norm (int, optional): The order embedding and distance normalization.\n",
    "            (default: :obj:`1.0`)\n",
    "        sparse (bool, optional): If set to :obj:`True`, gradients w.r.t. to the\n",
    "            embedding matrices will be sparse. (default: :obj:`False`)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        num_relations: int,\n",
    "        hidden_channels: int,\n",
    "        margin: float = 1.0,\n",
    "        p_norm: float = 1.0,\n",
    "        sparse: bool = False,\n",
    "    ):\n",
    "        super().__init__(num_nodes, num_relations, hidden_channels, sparse)\n",
    "\n",
    "        self.p_norm = p_norm\n",
    "        self.margin = margin\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        bound = 6. / math.sqrt(self.hidden_channels)\n",
    "        torch.nn.init.uniform_(self.node_emb.weight, -bound, bound)\n",
    "        torch.nn.init.uniform_(self.rel_emb.weight, -bound, bound)\n",
    "        F.normalize(self.rel_emb.weight.data, p=self.p_norm, dim=-1,\n",
    "                    out=self.rel_emb.weight.data)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        head_embeddings: Tensor,\n",
    "        rel_type,\n",
    "        tail_embeddings: Tensor,\n",
    "    ) -> Tensor:\n",
    "        #head = self.node_emb(head_index)\n",
    "        rel = self.rel_emb(rel_type)  # Amos: only learn the relation embeddings, others are learned with GNN\n",
    "        #tail = self.node_emb(tail_index)\n",
    "\n",
    "        head = F.normalize(head_embeddings, p=self.p_norm, dim=-1)\n",
    "        tail = F.normalize(tail_embeddings, p=self.p_norm, dim=-1)\n",
    "        # Calculate *negative* TransE norm:\n",
    "        negative_norm = -((head + rel) - tail).norm(p=self.p_norm, dim=-1)\n",
    "        return negative_norm\n",
    "\n",
    "    \n",
    "    def get_embedding(self,\n",
    "                      embedding,\n",
    "                    #   rel_type,\n",
    "                        # have_head_or_tail\n",
    "                      ):\n",
    "        # rel = self.rel_emb(rel_type)\n",
    "        embedding = F.normalize(embedding, p=self.p_norm, dim=-1)\n",
    "        # if have_head_or_tail == 'head':\n",
    "        #     return embedding + rel\n",
    "        # else:\n",
    "        #     return embedding - rel\n",
    "        return embedding\n",
    "    \n",
    "    def get_relationship_embedding(self,rel_type):\n",
    "        return self.rel_emb(rel_type)\n",
    "    \n",
    "    \n",
    "    def loss(\n",
    "        self,\n",
    "        head_embeddings: Tensor,\n",
    "        rel_type: Tensor,\n",
    "        tail_embeddings: Tensor,\n",
    "        labels: Tensor, # labels 0 or 1\n",
    "    ) -> Tensor:\n",
    "        pos_mask = labels == 1\n",
    "        neg_mask = labels == 0\n",
    "        \n",
    "        pos_score = self(head_embeddings[pos_mask], rel_type, tail_embeddings[pos_mask])\n",
    "        neg_score = self(head_embeddings[neg_mask], rel_type, tail_embeddings[neg_mask])\n",
    "        loss = F.margin_ranking_loss(\n",
    "            pos_score,\n",
    "            neg_score,\n",
    "            target=torch.ones_like(pos_score), # 1 for similarity, -1 for dissimilarity\n",
    "            margin=self.margin,\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HGTConv, Linear\n",
    "import torch \n",
    "\n",
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers, node_types, data_metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data_metadata,\n",
    "                           num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = {\n",
    "            node_type: self.lin_dict[node_type](x).relu_()\n",
    "            for node_type, x in x_dict.items()\n",
    "        }\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return x_dict\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "    # model = HGT(hidden_channels=64, out_channels=4, num_heads=2, num_layers=1, node_types=data.node_types, data_metadata=data.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (node_type_embedding): Embedding(5, 256)\n",
       "  (head): TransE(5, num_relations=13, hidden_channels=256)\n",
       "  (gnn): HGT(\n",
       "    (lin_dict): ModuleDict(\n",
       "      (author): Linear(-1, 256, bias=True)\n",
       "      (category): Linear(-1, 256, bias=True)\n",
       "      (journal): Linear(-1, 256, bias=True)\n",
       "      (paper): Linear(-1, 256, bias=True)\n",
       "      (word): Linear(-1, 256, bias=True)\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0-1): 2 x HGTConv(-1, 256, heads=8)\n",
       "    )\n",
       "    (lin): Linear(256, 256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# from models.TransE import TransE\n",
    "# from models.DistMult import DistMult\n",
    "# from models.HGT import HGT\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, gnn : torch.nn.Module, head :  torch.nn.Module, node_types, edge_types, ggn_output_dim, pnorm=1):\n",
    "        super().__init__()\n",
    "        # edge_type onehot lookup table with keys\n",
    "        # node_type onehot lookup table with keys\n",
    "        self.node_type_embedding = torch.nn.Embedding(len(node_types), ggn_output_dim) # hidden channels should be the output dim of gnn\n",
    "\n",
    "        self.edge_types = edge_types\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type[1].startswith('rev_'):\n",
    "                self.edge_types.remove(edge_type)\n",
    "\n",
    "        # create edge to int mapping\n",
    "        self.edgeindex_lookup = {edge_type:torch.tensor(i)  for i, edge_type in enumerate(edge_types)}\n",
    "\n",
    "        # hidden channels should be the output dim of gnn\n",
    "        if head=='TransE':\n",
    "            self.head = TransE(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm, margin=0.5)  # KGE head with loss function\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.gnn = gnn\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, hetero_data1, target_edge_type, edge_label_index, edge_label, hetero_data2=None, get_head_fn='loss'):\n",
    "\n",
    "        if hetero_data2 is not None:\n",
    "            assert target_edge_type[0] != target_edge_type[2], 'when passing two data objects, the edge type has to contain two different node types'\n",
    "            head_embeddings = self.gnn(hetero_data1.x_dict, hetero_data1.edge_index_dict)[target_edge_type[0]][edge_label_index[0,:]]\n",
    "            tail_embeddings = self.gnn(hetero_data2.x_dict, hetero_data2.edge_index_dict)[target_edge_type[2]][edge_label_index[1,:]]\n",
    "        else:\n",
    "            assert target_edge_type[0] == target_edge_type[2], 'when passing one data object, the edge type has to contain the same node types'\n",
    "\n",
    "\n",
    "            embeddings = self.gnn(hetero_data1.x_dict, hetero_data1.edge_index_dict)\n",
    "            head_embeddings = embeddings[target_edge_type[0]][edge_label_index[0,:]]\n",
    "            tail_embeddings = embeddings[target_edge_type[2]][edge_label_index[1,:]]\n",
    "        \n",
    "\n",
    "        edgeindex = self.edgeindex_lookup[target_edge_type]\n",
    "        if get_head_fn=='loss':\n",
    "            loss = self.head.loss(head_embeddings, edgeindex.to(device), tail_embeddings, edge_label)\n",
    "            return loss\n",
    "        elif get_head_fn=='forward':\n",
    "            return self.head.forward(head_embeddings, edgeindex.to(device), tail_embeddings)\n",
    "        \n",
    "    def get_embeddings(self, hetero_data, node_type, first_n_nodes):\n",
    "        embeddings = self.gnn(hetero_data.x_dict, hetero_data.edge_index_dict)[node_type][:first_n_nodes,:]\n",
    "        embeddings = self.head.get_embedding(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "    def get_relationship_embedding(self, edge_type):\n",
    "        return self.head.get_relationship_embedding(model.edgeindex_lookup[edge_type].cuda())\n",
    "\n",
    "metadata = data.metadata()\n",
    "# add selfloops\n",
    "for node_type in data.node_types:\n",
    "    metadata[1].append((node_type, 'self_loop', node_type))\n",
    "\n",
    "out_channels = 256\n",
    "hidden_channels = 256\n",
    "num_heads = 8\n",
    "num_layers = 2\n",
    "pnorm = 2\n",
    "head = 'TransE'\n",
    "gnn = HGT(hidden_channels=out_channels, out_channels=out_channels, num_heads=num_heads, num_layers=num_layers, node_types=data.node_types, data_metadata=metadata)\n",
    "\n",
    "model = Model(gnn, head=head, node_types=metadata[0], edge_types=metadata[1], ggn_output_dim=out_channels, pnorm=pnorm)\n",
    "#torch_geometric.compile(model, dynamic=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_node_types 5\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "# init model\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "batch_size = 32\n",
    "num_node_types = len(data.node_types)\n",
    "print('num_node_types', num_node_types)\n",
    "one_hop_neighbors = (20 * batch_size)//num_node_types # per relationship type\n",
    "two_hop_neighbors = (20 * 8 * batch_size)//num_node_types # per relationship type\n",
    "three_hop_neighbors = (20 * 8 * 3 * batch_size)//num_node_types # per relationship type\n",
    "num_neighbors = [one_hop_neighbors, two_hop_neighbors] # three_hop_neighbors\n",
    "\n",
    "from torch_geometric.loader import HGTLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(node_type):\n",
    "    \n",
    "    loader = HGTLoader(\n",
    "            data,\n",
    "            # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "            num_samples=num_neighbors,\n",
    "            batch_size=64, #96 or 32 nodes\n",
    "            input_nodes=node_type,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            prefetch_factor=None,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = HGTLoader(\n",
    "#             data,\n",
    "#             # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "#             num_samples=num_neighbors,\n",
    "#             batch_size=64, #96 or 32 nodes\n",
    "#             input_nodes=node_type,\n",
    "#             num_workers=4,\n",
    "#             pin_memory=True,\n",
    "#             prefetch_factor=None,\n",
    "#         )\n",
    "# minibatch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "category\n",
      "journal\n",
      "paper\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# init\n",
    "model.eval()\n",
    "for node_type in data.node_types:\n",
    "    print(node_type)\n",
    "    \n",
    "    loader = HGTLoader(\n",
    "            data,\n",
    "            # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "            num_samples=num_neighbors,\n",
    "            batch_size=64, #96 or 32 nodes\n",
    "            input_nodes=node_type,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            prefetch_factor=None,\n",
    "        )\n",
    "    minibatch = next(iter(loader))\n",
    "    \n",
    "    model.get_embeddings(minibatch.cuda(), node_type, first_n_nodes=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  author={\n",
       "    x=[434, 385],\n",
       "    n_id=[434],\n",
       "  },\n",
       "  category={\n",
       "    x=[92, 385],\n",
       "    n_id=[92],\n",
       "  },\n",
       "  journal={\n",
       "    x=[48, 385],\n",
       "    n_id=[48],\n",
       "  },\n",
       "  paper={\n",
       "    x=[1152, 400],\n",
       "    n_id=[1152],\n",
       "  },\n",
       "  word={\n",
       "    x=[1216, 386],\n",
       "    n_id=[1216],\n",
       "    input_id=[64],\n",
       "    batch_size=64,\n",
       "  },\n",
       "  (author, rev_written_by, paper)={\n",
       "    edge_index=[2, 411],\n",
       "    e_id=[411],\n",
       "  },\n",
       "  (category, rev_has_category, paper)={\n",
       "    edge_index=[2, 1648],\n",
       "    e_id=[1648],\n",
       "  },\n",
       "  (journal, rev_in_journal, paper)={\n",
       "    edge_index=[2, 729],\n",
       "    e_id=[729],\n",
       "  },\n",
       "  (paper, has_category, category)={\n",
       "    edge_index=[2, 2],\n",
       "    e_id=[2],\n",
       "  },\n",
       "  (paper, has_titleword, word)={\n",
       "    edge_index=[2, 209],\n",
       "    e_id=[209],\n",
       "  },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 366],\n",
       "    e_id=[366],\n",
       "  },\n",
       "  (paper, in_journal, journal)={\n",
       "    edge_index=[2, 47],\n",
       "    e_id=[47],\n",
       "  },\n",
       "  (paper, written_by, author)={\n",
       "    edge_index=[2, 384],\n",
       "    e_id=[384],\n",
       "  },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 1558],\n",
       "    e_id=[1558],\n",
       "  },\n",
       "  (word, rev_co_occurs_with, word)={\n",
       "    edge_index=[2, 1558],\n",
       "    e_id=[1558],\n",
       "  },\n",
       "  (word, rev_has_titleword, paper)={\n",
       "    edge_index=[2, 4742],\n",
       "    e_id=[4742],\n",
       "  },\n",
       "  (word, rev_has_word, paper)={\n",
       "    edge_index=[2, 6892],\n",
       "    e_id=[6892],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load state dict\n",
    "model_and_optimizer = torch.load('cache/runs/all_hgt_20240113_003259_mg05_norm2_lr0_0002_bs32_neigh_128_1024_h_TransE_hid_256_out_256_numh_8_numl_2/model_samplesseen144000.pt')\n",
    "model.load_state_dict(model_and_optimizer['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[-0.0187,  0.0200, -0.0051,  ...,  0.0610,  0.0057,  0.0390],\n",
       "        [-0.0636,  0.0415, -0.0116,  ...,  0.0699,  0.0469,  0.0111],\n",
       "        [-0.0832,  0.0122,  0.0189,  ..., -0.0008, -0.0708,  0.0419],\n",
       "        ...,\n",
       "        [-0.0215,  0.0772, -0.0655,  ...,  0.0012,  0.0276,  0.0010],\n",
       "        [-0.0740,  0.1247,  0.0085,  ..., -0.0013, -0.0143,  0.0010],\n",
       "        [ 0.0291,  0.0830, -0.0319,  ...,  0.0141,  0.0307,  0.0010]],\n",
       "       device='cuda:0'), 'n_id': tensor([ 574757,  118875,    8489,       2,  279889, 1315707,    5907,  564852,\n",
       "         878933,  214933, 1217613,       3,  880886, 1819963, 1766766,  532574,\n",
       "         581592,  251337, 1533046,  537412,  449671,   21633,  546957,  133737,\n",
       "         736075, 1421581,   49420,  517543, 1809497,   11259,  142743, 1819962,\n",
       "         125280,  957385,   35208,  560719, 1819961,  937233,       0,   47225,\n",
       "         888980,       1,  935556,  206517,  614296,  512782, 1235437, 1286483,\n",
       "        1387542, 1235438,   61879,  614298,   74220,  151584,   61881,    2027,\n",
       "         449672, 1152096,    7313,  878246,   82829,  705436,   51311,  354241,\n",
       "        1150556,  364989,  569603, 1286484, 1226635,  820280, 1186249,  490662,\n",
       "         281926,  937216,  614297, 1110667, 1186245,   68083, 1286485,  268046,\n",
       "         268049,  441670,  493110,  937253,    3423,  449670,  328082,  546474,\n",
       "         175144,  224140,  470242,   21577, 1331217,  119977,   59297, 1364953,\n",
       "        1874014,  822067,  518257,  488039,  642348,  157819,  449673,  449674,\n",
       "         449675,   12403,  348528,  240448,  561172,   15396,  686696,  892179,\n",
       "         244892,  931009,  424416,  952297, 1339374,  113451,   64282,  294439,\n",
       "         294440,  294441,  119033,  143928, 1021176,   73923,  204238,   82131,\n",
       "         918144,  705881,  666616,   46416,   91678, 1886055,   44815,   49828,\n",
       "         872329,   46771, 1446839,    7314,  617916,  413558, 1439103,  865230,\n",
       "        1110042, 1326556,   10734,  439037,   95970,   28829,  499702, 1718880,\n",
       "          33351,    4979,    4350,   29841, 1164091,   10857,    3239,   23703,\n",
       "          17786,  937248, 1442204,   23705,   88035, 1874111,   38641, 1877234,\n",
       "         108820,  243051,  302389,  455251,    4977, 1604891,  820475,   11680,\n",
       "          23165,   68084,    4981, 1164092,  850913,  717003, 1388393,  918145,\n",
       "         174291,   43968,   87755,  106705,   70207,  170287,  170288,  937244,\n",
       "          24777,   24778,   10232,  486056,  725150, 1578812,  937230,   10536,\n",
       "          10537,   10538,  581590,  154259,  155517,  210391,  571471,  607431,\n",
       "         227722,  121445, 1825681, 1387539,    4146,  135021,   31703,  467354,\n",
       "         453087,  223971,  223974,  125988,  229299, 1280877,  293252,  488040,\n",
       "          76309,   95319,  115550,  175551,  794876,  983223, 1443899,   73916,\n",
       "          83555, 1280878,  139330, 1210435, 1394521,  250787,  352955,  878938,\n",
       "          78158,  242979,  565802,  816376, 1233092, 1421580,  580252, 1843665,\n",
       "          11282,   24126,  782556,  381448, 1247529, 1761066, 1280875, 1280876,\n",
       "         128941,  295788, 1280879,  791789,  161052,  149557,  282859,  224840,\n",
       "         505205,  505206,    9969, 1387538,  490576,   67480, 1826625,  878935,\n",
       "          54935,  794228, 1829205,   20513,  112145,  126831,  582622, 1703129,\n",
       "        1876369, 1225198, 1354885,   14563,  270443,  321154,  799379,  799380,\n",
       "          51072,  131631,  404984, 1199724,   50020, 1226642,  288909,  466722,\n",
       "         964969, 1152054, 1266964,   13137,   48545, 1383165,  937240,  170609,\n",
       "         350429, 1387536,  527129,  174290, 1387537, 1387540, 1387541,  566195,\n",
       "         194162, 1387543,  273980,  393648,  622607,  878932, 1774245,  878934,\n",
       "         878936,  878937,  909185,  878939,  205823,  218047,   87363,  189704,\n",
       "         338537,  721334,  191209,  365242,   92394,  607430,   29101,   32966,\n",
       "        1295611,  496019,  295787,  295789,  143200,  295790,  428306,    4978,\n",
       "           4980,    4982,   22084,   26326,  228210,  125892,  181569,  192689,\n",
       "         921673,   21667,   31131,   31142,   94677,   89933,   89934, 1869066,\n",
       "         154588,  227456,   34138,   74163,  631569,  270654, 1814878,  293584,\n",
       "          13521,    8822,   11829,   14291,   34139,   23097,   73438,  729011,\n",
       "        1226633, 1226639, 1226640, 1226641,  291132,  565803,  581599,  537404,\n",
       "         357595,  328081,  937213,  931484,  937214,  123147,  295904,  937224,\n",
       "         937225,  382273,  464023,  937229,  272635,  304361,  581596,  914244,\n",
       "         269729,  532720,  537429,  254013,  937247,  207491,  937250,  937239,\n",
       "          17782,   17783,   17784,   17785,   17787,  935122,   96164,  396149,\n",
       "         672773,  338358,  919788,  232201,  408010,  586141,  710529, 1392789,\n",
       "         484757,  690595,  836902,  935121,  244910,  432625,  646770, 1421579,\n",
       "         929925, 1043329], device='cuda:0')}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/38514 [00:00<8:34:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1929350, 1234238, 1052857,   24176, 1062789, 2218334, 1021327, 1553884,\n",
      "         334198, 2387895, 1955452, 1524628, 1832836, 1791221, 2291320, 1234940,\n",
      "        2285470,  983243, 2452261,  157912, 1051691,  896719, 1803973, 1336140,\n",
      "        2041420, 1962366,  646210,  430938, 1788147,  917328,  365214, 2420617,\n",
      "        2097264,  861585, 2289217, 1521202,  724826,  310666,  867373, 1779422,\n",
      "        1892927,  976410, 1897790, 1511447,  490173,  232810, 1237916, 2207901,\n",
      "         282487, 1517768, 1003755,  802259,  273517, 1990207, 2199369,  310526,\n",
      "          24626, 2233566, 1794842, 1347469, 2222332, 1926640, 2334614, 1207183],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/38514 [00:01<8:01:42,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2352534, 1118889, 1833076, 1495366, 1707582, 2131318, 1826475, 1960888,\n",
      "         418856, 2268695, 1513982,  904619, 1145331,  549565,  382744,  911450,\n",
      "         668794,  434865, 1244411, 1580404, 2240430, 1827070, 1024289, 1366218,\n",
      "        1526758,  361713, 1020940, 1400037, 1656216, 1044190,   68146, 2209638,\n",
      "         132706,  399811, 1375511, 1229170,   23393,  570548, 1497944,  682022,\n",
      "        2268862, 2282350,  756856,  704053, 2197343,  301648, 2082394, 1917085,\n",
      "         562194, 2051955,  522113, 2422560, 1823937, 1846828,  256785, 2184119,\n",
      "          22300, 1928596, 2089044, 1571096,  908107, 2254253,  324958, 1605999],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/38514 [00:02<7:12:58,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1643097, 1117584, 1734158, 2284907,  112186,  580848,  164502,  123386,\n",
      "         405493,  682864, 1310955,  481352,  298911,  619920, 1280591,   31756,\n",
      "        1145425, 1465802, 1762216, 2294221, 1934642, 1441156, 1038040, 1172363,\n",
      "        1033701,  876439, 1328757, 1139169, 2428074, 2190089, 1106117, 1356273,\n",
      "        1862284, 1108181,  259659, 1260329,  716359,   59948,  684694,  892477,\n",
      "        2419862, 2154552, 1578410, 1067506,  712412, 1296457,  144309,  704041,\n",
      "         105701,  824653, 1082605, 1706165, 1458115,  170907,  616559,  357668,\n",
      "         825183, 1113146, 1334531,  461522, 1268622,  389055,  980914,  835528],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/38514 [00:02<8:51:47,  1.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m minibatch \u001b[38;5;129;01min\u001b[39;00m tqdm(loader):\n\u001b[1;32m---> 30\u001b[0m     embds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminibatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_n_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m     31\u001b[0m     n_ids \u001b[38;5;241m=\u001b[39m minibatch[node_type]\u001b[38;5;241m.\u001b[39mn_id[:batch_size]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(n_ids)\n",
      "Cell \u001b[1;32mIn[5], line 55\u001b[0m, in \u001b[0;36mModel.get_embeddings\u001b[1;34m(self, hetero_data, node_type, first_n_nodes)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, hetero_data, node_type, first_n_nodes):\n\u001b[1;32m---> 55\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhetero_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhetero_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m[node_type][:first_n_nodes,:]\n\u001b[0;32m     56\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mget_embedding(embeddings)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m, in \u001b[0;36mHGT.forward\u001b[1;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m     21\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     22\u001b[0m     node_type: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_dict[node_type](x)\u001b[38;5;241m.\u001b[39mrelu_()\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node_type, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     24\u001b[0m }\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[1;32m---> 27\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_dict\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch_geometric\\nn\\conv\\hgt_conv.py:196\u001b[0m, in \u001b[0;36mHGTConv.forward\u001b[1;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m    193\u001b[0m     v_dict[key] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H, D)\n\u001b[0;32m    195\u001b[0m q, dst_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cat(q_dict)\n\u001b[1;32m--> 196\u001b[0m k, v, src_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_src_node_feat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m edge_index, edge_attr \u001b[38;5;241m=\u001b[39m construct_bipartite_edge_index(\n\u001b[0;32m    200\u001b[0m     edge_index_dict, src_offset, dst_offset, edge_attr_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_rel)\n\u001b[0;32m    202\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, k\u001b[38;5;241m=\u001b[39mk, q\u001b[38;5;241m=\u001b[39mq, v\u001b[38;5;241m=\u001b[39mv, edge_attr\u001b[38;5;241m=\u001b[39medge_attr,\n\u001b[0;32m    203\u001b[0m                      size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch_geometric\\nn\\conv\\hgt_conv.py:156\u001b[0m, in \u001b[0;36mHGTConv._construct_src_node_feat\u001b[1;34m(self, k_dict, v_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m    153\u001b[0m type_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(type_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    155\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_rel(ks, type_vec)\u001b[38;5;241m.\u001b[39mview(H, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, D)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 156\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_rel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_vec\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(H, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, D)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m k, v, offset\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:278\u001b[0m, in \u001b[0;36mHeteroLinear.forward\u001b[1;34m(self, x, type_vec)\u001b[0m\n\u001b[0;32m    276\u001b[0m     subset_out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x[mask], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[i]\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# The data type may have changed with mixed precision:\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m     out[mask] \u001b[38;5;241m=\u001b[39m subset_out\u001b[38;5;241m.\u001b[39mto(out\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[type_vec]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for node_type in data.node_types:\n",
    "        batch_size = {\n",
    "            'paper': 32,\n",
    "            'author': 64,\n",
    "            'word': 64,\n",
    "            'journal': 64,\n",
    "            'category': 64,\n",
    "            }[node_type]\n",
    "        \n",
    "        print(node_type)\n",
    "        \n",
    "        \n",
    "        loader = HGTLoader(\n",
    "                data,\n",
    "                # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "                num_samples=num_neighbors,\n",
    "                batch_size=batch_size, #96 or 32 nodes\n",
    "                input_nodes=node_type,\n",
    "                num_workers=2,\n",
    "                pin_memory=True,\n",
    "                prefetch_factor=2,\n",
    "                drop_last=False,\n",
    "                shuffle=True\n",
    "            )\n",
    "        \n",
    "        embeddings = []\n",
    "        indices = []\n",
    "        for minibatch in tqdm(loader):\n",
    "            embds = model.get_embeddings(minibatch.cuda(), node_type, first_n_nodes=batch_size).cpu()\n",
    "            n_ids = minibatch[node_type].n_id[:batch_size]\n",
    "            embeddings.append(embds)\n",
    "            indices.append(n_ids)\n",
    "            # for i, n_id in enumerate(n_ids):\n",
    "                # embeddings[n_id.item()] = embds[i,:]\n",
    "        embeddings = torch.cat(embeddings)\n",
    "        indices = torch.cat(indices)\n",
    "        torch.save({'embeddings':embeddings, 'indices':indices}, f'embeddings_{node_type}.pt')\n",
    "        \n",
    "    for edge_type in data.edge_types:\n",
    "        if 'rev_' in edge_type[1]:\n",
    "            continue\n",
    "        \n",
    "        rel_embd = model.get_relationship_embedding(edge_type)\n",
    "        torch.save({'embedding':edge_type}, f'relationship_embedding_{\"_\".join(edge_type)}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.edgeindex_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnpapersearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
