{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\I549512\\AppData\\Local\\miniconda3\\envs\\gnnpapersearch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "dataset = pickle.load(open(\"arxiv_author_paper_graph_training_v1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    num_nodes=1000,\n",
       "    x=[1000, 388],\n",
       "  },\n",
       "  author={\n",
       "    num_nodes=2886,\n",
       "    x=[2886, 384],\n",
       "  },\n",
       "  category={\n",
       "    num_nodes=108,\n",
       "    x=[108, 384],\n",
       "  },\n",
       "  word={\n",
       "    num_nodes=10604,\n",
       "    x=[10604, 384],\n",
       "  },\n",
       "  journal={\n",
       "    num_nodes=574,\n",
       "    x=[574, 384],\n",
       "  },\n",
       "  (paper, written_by, author)={ edge_index=[2, 3067] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 1502] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 57073],\n",
       "    edge_attr=[57073],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 7354] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 1000] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 871906],\n",
       "    edge_attr=[871906],\n",
       "  },\n",
       "  (author, rev_written_by, paper)={ edge_index=[2, 3067] },\n",
       "  (category, rev_has_category, paper)={ edge_index=[2, 1502] },\n",
       "  (word, rev_has_word, paper)={\n",
       "    edge_index=[2, 57073],\n",
       "    edge_attr=[57073],\n",
       "  },\n",
       "  (word, rev_has_titleword, paper)={ edge_index=[2, 7354] },\n",
       "  (journal, rev_in_journal, paper)={ edge_index=[2, 1000] }\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    num_nodes=1000,\n",
       "    x=[1000, 388],\n",
       "  },\n",
       "  author={\n",
       "    num_nodes=2886,\n",
       "    x=[2886, 384],\n",
       "  },\n",
       "  category={\n",
       "    num_nodes=108,\n",
       "    x=[108, 384],\n",
       "  },\n",
       "  word={\n",
       "    num_nodes=10604,\n",
       "    x=[10604, 384],\n",
       "  },\n",
       "  journal={\n",
       "    num_nodes=574,\n",
       "    x=[574, 384],\n",
       "  },\n",
       "  (paper, written_by, author)={ edge_index=[2, 3067] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 1502] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 57073],\n",
       "    edge_attr=[57073],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 7354] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 1000] },\n",
       "  (word, co_occurs_with, word)={\n",
       "    edge_index=[2, 871906],\n",
       "    edge_attr=[871906],\n",
       "  },\n",
       "  (author, rev_written_by, paper)={ edge_index=[2, 3067] },\n",
       "  (category, rev_has_category, paper)={ edge_index=[2, 1502] },\n",
       "  (word, rev_has_word, paper)={\n",
       "    edge_index=[2, 57073],\n",
       "    edge_attr=[57073],\n",
       "  },\n",
       "  (word, rev_has_titleword, paper)={ edge_index=[2, 7354] },\n",
       "  (journal, rev_in_journal, paper)={ edge_index=[2, 1000] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save paper.pt\n",
      "save author.pt\n",
      "save category.pt\n",
      "save word.pt\n",
      "save journal.pt\n",
      "save paper_written_by_author.pt\n",
      "save paper_has_category_category.pt\n",
      "save paper_has_word_word.pt\n",
      "save paper_has_titleword_word.pt\n",
      "save paper_in_journal_journal.pt\n",
      "save word_co_occurs_with_word.pt\n",
      "save author_rev_written_by_paper.pt\n",
      "save category_rev_has_category_paper.pt\n",
      "save word_rev_has_word_paper.pt\n",
      "save word_rev_has_titleword_paper.pt\n",
      "save journal_rev_in_journal_paper.pt\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "def save_heterograph_dataset(dataset, folder):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    for edge_or_node_type in dataset.node_types+dataset.edge_types:\n",
    "        if isinstance(edge_or_node_type, tuple):\n",
    "            name = '_'.join(edge_or_node_type) + \".pt\"\n",
    "        else:\n",
    "            name = edge_or_node_type + \".pt\"\n",
    "        data = {}\n",
    "        print('save', name)\n",
    "        for key, value in dataset[edge_or_node_type].items():\n",
    "            data[key] = value\n",
    "        torch.save({'name':edge_or_node_type, 'attributes':data}, os.path.join(folder, name))\n",
    "\n",
    "save_heterograph_dataset(dataset, \"train_data_arxiv_paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "def load_heterograph_dataset(folder):\n",
    "    dataset = HeteroData()\n",
    "    for name in os.listdir(folder):\n",
    "        print('load', name)\n",
    "        path = os.path.join(folder, name)\n",
    "        if os.path.isfile(path):\n",
    "            data = torch.load(path)\n",
    "            for key, value in data['attributes'].items():\n",
    "                dataset[data['name']][key] = value\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save paper.pt\n",
      "save author.pt\n",
      "save category.pt\n",
      "save word.pt\n",
      "save journal.pt\n",
      "save paper_written_by_author.pt\n",
      "save paper_has_category_category.pt\n",
      "save paper_has_word_word.pt\n",
      "save paper_has_titleword_word.pt\n",
      "save paper_in_journal_journal.pt\n",
      "save word_co_occurs_with_word.pt\n",
      "save author_rev_written_by_paper.pt\n",
      "save category_rev_has_category_paper.pt\n",
      "save word_rev_has_word_paper.pt\n",
      "save word_rev_has_titleword_paper.pt\n",
      "save journal_rev_in_journal_paper.pt\n"
     ]
    }
   ],
   "source": [
    "dataset = pickle.load(open(\"arxiv_author_paper_graph_no_features_bare.pkl\", \"rb\"))\n",
    "save_heterograph_dataset(dataset, \"whole_graph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load author.pt\n",
      "load author_rev_written_by_paper.pt\n",
      "load category.pt\n",
      "load category_rev_has_category_paper.pt\n",
      "load journal.pt\n",
      "load journal_rev_in_journal_paper.pt\n",
      "load paper.pt\n",
      "load paper_has_category_category.pt\n",
      "load paper_has_titleword_word.pt\n",
      "load paper_has_word_word.pt\n",
      "load paper_in_journal_journal.pt\n",
      "load paper_written_by_author.pt\n",
      "load word.pt\n",
      "load word_co_occurs_with_word.pt\n",
      "load word_rev_has_titleword_paper.pt\n",
      "load word_rev_has_word_paper.pt\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_heterograph_dataset(\"train_data_arxiv_paper\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnpapersearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
