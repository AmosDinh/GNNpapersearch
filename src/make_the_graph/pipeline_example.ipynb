{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/arxiv-metadata-oai-snapshot-10000.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pages(s):\n",
    "    match = re.search(r\"(\\d+)\\s*pages\", s)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>37 pages, 15 figures; published version</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>ANL-HEP-PR-07-12</td>\n",
       "      <td>[hep-ph]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[Balázs C., Berger E. L., Nadolsky P. M., Yuan...</td>\n",
       "      <td>1.175542e+09</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>To appear in Graphs and Combinatorics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[math.CO, cs.CG]</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[Streinu Ileana, Theran Louis]</td>\n",
       "      <td>1.175308e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.0003</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>23 pages, 3 figures</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[physics.gen-ph]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>[Pan Hongjun]</td>\n",
       "      <td>1.175460e+09</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.0004</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>11 pages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[math.CO]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>[Callan David]</td>\n",
       "      <td>1.175311e+09</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.0005</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Illinois J. Math. 52 (2008) no.2, 681-689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[math.CA, math.FA]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>[Abu-Shammala Wael, Torchinsky Alberto]</td>\n",
       "      <td>1.175537e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  704.0001  Calculation of prompt diphoton production cros...   \n",
       "1  704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2  704.0003  The evolution of the Earth-Moon system based o...   \n",
       "3  704.0004  A determinant of Stirling cycle numbers counts...   \n",
       "4  704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "\n",
       "                                  comments  \\\n",
       "0  37 pages, 15 figures; published version   \n",
       "1    To appear in Graphs and Combinatorics   \n",
       "2                      23 pages, 3 figures   \n",
       "3                                 11 pages   \n",
       "4                                      NaN   \n",
       "\n",
       "                                 journal-ref                         doi  \\\n",
       "0                   Phys.Rev.D76:013009,2007  10.1103/PhysRevD.76.013009   \n",
       "1                                        NaN                         NaN   \n",
       "2                                        NaN                         NaN   \n",
       "3                                        NaN                         NaN   \n",
       "4  Illinois J. Math. 52 (2008) no.2, 681-689                         NaN   \n",
       "\n",
       "          report-no          categories  \\\n",
       "0  ANL-HEP-PR-07-12            [hep-ph]   \n",
       "1               NaN    [math.CO, cs.CG]   \n",
       "2               NaN    [physics.gen-ph]   \n",
       "3               NaN           [math.CO]   \n",
       "4               NaN  [math.CA, math.FA]   \n",
       "\n",
       "                                             license  \\\n",
       "0                                                NaN   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A fully differential calculation in perturba...   \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2    The evolution of Earth-Moon system is descri...   \n",
       "3    We show that a determinant of Stirling cycle...   \n",
       "4    In this paper we show how to compute the $\\L...   \n",
       "\n",
       "                                      authors_parsed     timestamp  pages  \n",
       "0  [Balázs C., Berger E. L., Nadolsky P. M., Yuan...  1.175542e+09   37.0  \n",
       "1                     [Streinu Ileana, Theran Louis]  1.175308e+09    NaN  \n",
       "2                                      [Pan Hongjun]  1.175460e+09   23.0  \n",
       "3                                     [Callan David]  1.175311e+09   11.0  \n",
       "4            [Abu-Shammala Wael, Torchinsky Alberto]  1.175537e+09    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors_parsed'] = df['authors_parsed'].apply(lambda x: [\" \".join(i).strip() for i in eval(x)])\n",
    "df['versions'] = df['versions'].apply(lambda x: eval(x)[0][\"created\"])\n",
    "df['timestamp'] = pd.to_datetime(df['versions'], format=\"%a, %d %b %Y %H:%M:%S %Z\")\n",
    "df['timestamp'] = df['timestamp'].apply(lambda x: x.timestamp())\n",
    "df[\"categories\"] = df[\"categories\"].apply(lambda x: x.split(\" \"))\n",
    "df.drop(columns=[\"submitter\", \"versions\", \"update_date\", \"authors\"], inplace=True)\n",
    "df[\"pages\"] = df.comments.apply(lambda x: extract_pages(str(x)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_normalize(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [token.text.lower() for token in doc if not token.is_punct and not token.is_space]\n",
    "\n",
    "def lemm(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if not token.is_punct and not token.is_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'fully', 'differential', 'calculation', 'in', 'perturbative', 'quantum', 'chromodynamics', 'is', 'presented', 'for', 'the', 'production', 'of', 'massive', 'photon', 'pairs', 'at', 'hadron', 'colliders', 'all', 'next', 'to', 'leading', 'order', 'perturbative', 'contributions', 'from', 'quark', 'antiquark', 'gluon-(anti)quark', 'and', 'gluon', 'gluon', 'subprocesses', 'are', 'included', 'as', 'well', 'as', 'all', 'orders', 'resummation', 'of', 'initial', 'state', 'gluon', 'radiation', 'valid', 'at', 'next', 'to', 'next', 'to', 'leading', 'logarithmic', 'accuracy', 'the', 'region', 'of', 'phase', 'space', 'is', 'specified', 'in', 'which', 'the', 'calculation', 'is', 'most', 'reliable', 'good', 'agreement', 'is', 'demonstrated', 'with', 'data', 'from', 'the', 'fermilab', 'tevatron', 'and', 'predictions', 'are', 'made', 'for', 'more', 'detailed', 'tests', 'with', 'cdf', 'and', 'do', 'data', 'predictions', 'are', 'shown', 'for', 'distributions', 'of', 'diphoton', 'pairs', 'produced', 'at', 'the', 'energy', 'of', 'the', 'large', 'hadron', 'collider', 'lhc', 'distributions', 'of', 'the', 'diphoton', 'pairs', 'from', 'the', 'decay', 'of', 'a', 'higgs', 'boson', 'are', 'contrasted', 'with', 'those', 'produced', 'from', 'qcd', 'processes', 'at', 'the', 'lhc', 'showing', 'that', 'enhanced', 'sensitivity', 'to', 'the', 'signal', 'can', 'be', 'obtained', 'with', 'judicious', 'selection', 'of', 'events'], ['we', 'describe', 'a', 'new', 'algorithm', 'the', '$', 'k,\\\\ell)$-pebble', 'game', 'with', 'colors', 'and', 'use', 'it', 'obtain', 'a', 'characterization', 'of', 'the', 'family', 'of', '$', 'k,\\\\ell)$-sparse', 'graphs', 'and', 'algorithmic', 'solutions', 'to', 'a', 'family', 'of', 'problems', 'concerning', 'tree', 'decompositions', 'of', 'graphs', 'special', 'instances', 'of', 'sparse', 'graphs', 'appear', 'in', 'rigidity', 'theory', 'and', 'have', 'received', 'increased', 'attention', 'in', 'recent', 'years', 'in', 'particular', 'our', 'colored', 'pebbles', 'generalize', 'and', 'strengthen', 'the', 'previous', 'results', 'of', 'lee', 'and', 'streinu', 'and', 'give', 'a', 'new', 'proof', 'of', 'the', 'tutte', 'nash', 'williams', 'characterization', 'of', 'arboricity', 'we', 'also', 'present', 'a', 'new', 'decomposition', 'that', 'certifies', 'sparsity', 'based', 'on', 'the', '$', 'k,\\\\ell)$-pebble', 'game', 'with', 'colors', 'our', 'work', 'also', 'exposes', 'connections', 'between', 'pebble', 'game', 'algorithms', 'and', 'previous', 'sparse', 'graph', 'algorithms', 'by', 'gabow', 'gabow', 'and', 'westermann', 'and', 'hendrickson'], ['the', 'evolution', 'of', 'earth', 'moon', 'system', 'is', 'described', 'by', 'the', 'dark', 'matter', 'field', 'fluid', 'model', 'proposed', 'in', 'the', 'meeting', 'of', 'division', 'of', 'particle', 'and', 'field', '2004', 'american', 'physical', 'society', 'the', 'current', 'behavior', 'of', 'the', 'earth', 'moon', 'system', 'agrees', 'with', 'this', 'model', 'very', 'well', 'and', 'the', 'general', 'pattern', 'of', 'the', 'evolution', 'of', 'the', 'moon', 'earth', 'system', 'described', 'by', 'this', 'model', 'agrees', 'with', 'geological', 'and', 'fossil', 'evidence', 'the', 'closest', 'distance', 'of', 'the', 'moon', 'to', 'earth', 'was', 'about', '259000', 'km', 'at', '4.5', 'billion', 'years', 'ago', 'which', 'is', 'far', 'beyond', 'the', 'roche', \"'s\", 'limit', 'the', 'result', 'suggests', 'that', 'the', 'tidal', 'friction', 'may', 'not', 'be', 'the', 'primary', 'cause', 'for', 'the', 'evolution', 'of', 'the', 'earth', 'moon', 'system', 'the', 'average', 'dark', 'matter', 'field', 'fluid', 'constant', 'derived', 'from', 'earth', 'moon', 'system', 'data', 'is', '4.39', 'x', '10^(-22', 's^(-1)m^(-1', 'this', 'model', 'predicts', 'that', 'the', 'mars', \"'s\", 'rotation', 'is', 'also', 'slowing', 'with', 'the', 'angular', 'acceleration', 'rate', 'about', '-4.38', 'x', '10^(-22', 'rad', 's^(-2'], ['we', 'show', 'that', 'a', 'determinant', 'of', 'stirling', 'cycle', 'numbers', 'counts', 'unlabeled', 'acyclic', 'single', 'source', 'automata', 'the', 'proof', 'involves', 'a', 'bijection', 'from', 'these', 'automata', 'to', 'certain', 'marked', 'lattice', 'paths', 'and', 'a', 'sign', 'reversing', 'involution', 'to', 'evaluate', 'the', 'determinant'], ['in', 'this', 'paper', 'we', 'show', 'how', 'to', 'compute', 'the', '$', '\\\\lambda_{\\\\alpha}$', 'norm', '$', '\\\\alpha\\\\ge', '0', '$', 'using', 'the', 'dyadic', 'grid', 'this', 'result', 'is', 'a', 'consequence', 'of', 'the', 'description', 'of', 'the', 'hardy', 'spaces', '$', 'h^p(r^n)$', 'in', 'terms', 'of', 'dyadic', 'and', 'special', 'atoms'], ['we', 'study', 'the', 'two', 'particle', 'wave', 'function', 'of', 'paired', 'atoms', 'in', 'a', 'fermi', 'gas', 'with', 'tunable', 'interaction', 'strengths', 'controlled', 'by', 'feshbach', 'resonance', 'the', 'cooper', 'pair', 'wave', 'function', 'is', 'examined', 'for', 'its', 'bosonic', 'characters', 'which', 'is', 'quantified', 'by', 'the', 'correction', 'of', 'bose', 'enhancement', 'factor', 'associated', 'with', 'the', 'creation', 'and', 'annihilation', 'composite', 'particle', 'operators', 'an', 'example', 'is', 'given', 'for', 'a', 'three', 'dimensional', 'uniform', 'gas', 'two', 'definitions', 'of', 'cooper', 'pair', 'wave', 'function', 'are', 'examined', 'one', 'of', 'which', 'is', 'chosen', 'to', 'reflect', 'the', 'off', 'diagonal', 'long', 'range', 'order', 'odlro', 'another', 'one', 'corresponds', 'to', 'a', 'pair', 'projection', 'of', 'a', 'bcs', 'state', 'on', 'the', 'side', 'with', 'negative', 'scattering', 'length', 'we', 'found', 'that', 'paired', 'atoms', 'described', 'by', 'odlro', 'are', 'more', 'bosonic', 'than', 'the', 'pair', 'projected', 'definition', 'it', 'is', 'also', 'found', 'that', 'at', '$', 'k_f', 'a)^{-1', '\\\\ge', '1', '$', 'both', 'definitions', 'give', 'similar', 'results', 'where', 'more', 'than', '90', 'of', 'the', 'atoms', 'occupy', 'the', 'corresponding', 'molecular', 'condensates'], ['a', 'rather', 'non', 'standard', 'quantum', 'representation', 'of', 'the', 'canonical', 'commutation', 'relations', 'of', 'quantum', 'mechanics', 'systems', 'known', 'as', 'the', 'polymer', 'representation', 'has', 'gained', 'some', 'attention', 'in', 'recent', 'years', 'due', 'to', 'its', 'possible', 'relation', 'with', 'planck', 'scale', 'physics', 'in', 'particular', 'this', 'approach', 'has', 'been', 'followed', 'in', 'a', 'symmetric', 'sector', 'of', 'loop', 'quantum', 'gravity', 'known', 'as', 'loop', 'quantum', 'cosmology', 'here', 'we', 'explore', 'different', 'aspects', 'of', 'the', 'relation', 'between', 'the', 'ordinary', 'schroedinger', 'theory', 'and', 'the', 'polymer', 'description', 'the', 'paper', 'has', 'two', 'parts', 'in', 'the', 'first', 'one', 'we', 'derive', 'the', 'polymer', 'quantum', 'mechanics', 'starting', 'from', 'the', 'ordinary', 'schroedinger', 'theory', 'and', 'show', 'that', 'the', 'polymer', 'description', 'arises', 'as', 'an', 'appropriate', 'limit', 'in', 'the', 'second', 'part', 'we', 'consider', 'the', 'continuum', 'limit', 'of', 'this', 'theory', 'namely', 'the', 'reverse', 'process', 'in', 'which', 'one', 'starts', 'from', 'the', 'discrete', 'theory', 'and', 'tries', 'to', 'recover', 'back', 'the', 'ordinary', 'schroedinger', 'quantum', 'mechanics', 'we', 'consider', 'several', 'examples', 'of', 'interest', 'including', 'the', 'harmonic', 'oscillator', 'the', 'free', 'particle', 'and', 'a', 'simple', 'cosmological', 'model'], ['a', 'general', 'formulation', 'was', 'developed', 'to', 'represent', 'material', 'models', 'for', 'applications', 'in', 'dynamic', 'loading', 'numerical', 'methods', 'were', 'devised', 'to', 'calculate', 'response', 'to', 'shock', 'and', 'ramp', 'compression', 'and', 'ramp', 'decompression', 'generalizing', 'previous', 'solutions', 'for', 'scalar', 'equations', 'of', 'state', 'the', 'numerical', 'methods', 'were', 'found', 'to', 'be', 'flexible', 'and', 'robust', 'and', 'matched', 'analytic', 'results', 'to', 'a', 'high', 'accuracy', 'the', 'basic', 'ramp', 'and', 'shock', 'solution', 'methods', 'were', 'coupled', 'to', 'solve', 'for', 'composite', 'deformation', 'paths', 'such', 'as', 'shock', 'induced', 'impacts', 'and', 'shock', 'interactions', 'with', 'a', 'planar', 'interface', 'between', 'different', 'materials', 'these', 'calculations', 'capture', 'much', 'of', 'the', 'physics', 'of', 'typical', 'material', 'dynamics', 'experiments', 'without', 'requiring', 'spatially', 'resolving', 'simulations', 'example', 'calculations', 'were', 'made', 'of', 'loading', 'histories', 'in', 'metals', 'illustrating', 'the', 'effects', 'of', 'plastic', 'work', 'on', 'the', 'temperatures', 'induced', 'in', 'quasi', 'isentropic', 'and', 'shock', 'release', 'experiments', 'and', 'the', 'effect', 'of', 'a', 'phase', 'transition'], ['we', 'discuss', 'the', 'results', 'from', 'the', 'combined', 'irac', 'and', 'mips', 'c2d', 'spitzer', 'legacy', 'observations', 'of', 'the', 'serpens', 'star', 'forming', 'region', 'in', 'particular', 'we', 'present', 'a', 'set', 'of', 'criteria', 'for', 'isolating', 'bona', 'fide', 'young', 'stellar', 'objects', 'yso', \"'s\", 'from', 'the', 'extensive', 'background', 'contamination', 'by', 'extra', 'galactic', 'objects', 'we', 'then', 'discuss', 'the', 'properties', 'of', 'the', 'resulting', 'high', 'confidence', 'set', 'of', 'yso', \"'s\", 'we', 'find', '235', 'such', 'objects', 'in', 'the', '0.85', 'deg^2', 'field', 'that', 'was', 'covered', 'with', 'both', 'irac', 'and', 'mips', 'an', 'additional', 'set', 'of', '51', 'lower', 'confidence', 'yso', \"'s\", 'outside', 'this', 'area', 'is', 'identified', 'from', 'the', 'mips', 'data', 'combined', 'with', '2mass', 'photometry', 'we', 'describe', 'two', 'sets', 'of', 'results', 'color', 'color', 'diagrams', 'to', 'compare', 'our', 'observed', 'source', 'properties', 'with', 'those', 'of', 'theoretical', 'models', 'for', 'star', 'disk', 'envelope', 'systems', 'and', 'our', 'own', 'modeling', 'of', 'the', 'subset', 'of', 'our', 'objects', 'that', 'appear', 'to', 'be', 'star+disks', 'these', 'objects', 'exhibit', 'a', 'very', 'wide', 'range', 'of', 'disk', 'properties', 'from', 'many', 'that', 'can', 'be', 'fit', 'with', 'actively', 'accreting', 'disks', 'to', 'some', 'with', 'both', 'passive', 'disks', 'and', 'even', 'possibly', 'debris', 'disks', 'we', 'find', 'that', 'the', 'luminosity', 'function', 'of', 'yso', \"'s\", 'in', 'serpens', 'extends', 'down', 'to', 'at', 'least', 'a', 'few', 'x', '.001', 'lsun', 'or', 'lower', 'for', 'an', 'assumed', 'distance', 'of', '260', 'pc', 'the', 'lower', 'limit', 'may', 'be', 'set', 'by', 'our', 'inability', 'to', 'distinguish', 'yso', \"'s\", 'from', 'extra', 'galactic', 'sources', 'more', 'than', 'by', 'the', 'lack', 'of', 'yso', \"'s\", 'at', 'very', 'low', 'luminosities', 'a', 'spatial', 'clustering', 'analysis', 'shows', 'that', 'the', 'nominally', 'less', 'evolved', 'yso', \"'s\", 'are', 'more', 'highly', 'clustered', 'than', 'the', 'later', 'stages', 'and', 'that', 'the', 'background', 'extra', 'galactic', 'population', 'can', 'be', 'fit', 'by', 'the', 'same', 'two', 'point', 'correlation', 'function', 'as', 'seen', 'in', 'other', 'extra', 'galactic', 'studies', 'we', 'also', 'present', 'a', 'table', 'of', 'matches', 'between', 'several', 'previous', 'infrared', 'and', 'x', 'ray', 'studies', 'of', 'the', 'serpens', 'yso', 'population', 'and', 'our', 'spitzer', 'data', 'set'], ['partial', 'cubes', 'are', 'isometric', 'subgraphs', 'of', 'hypercubes', 'structures', 'on', 'a', 'graph', 'defined', 'by', 'means', 'of', 'semicubes', 'and', \"djokovi\\\\'{c\", \"'s\", 'and', 'winkler', \"'s\", 'relations', 'play', 'an', 'important', 'role', 'in', 'the', 'theory', 'of', 'partial', 'cubes', 'these', 'structures', 'are', 'employed', 'in', 'the', 'paper', 'to', 'characterize', 'bipartite', 'graphs', 'and', 'partial', 'cubes', 'of', 'arbitrary', 'dimension', 'new', 'characterizations', 'are', 'established', 'and', 'new', 'proofs', 'of', 'some', 'known', 'results', 'are', 'given', 'the', 'operations', 'of', 'cartesian', 'product', 'and', 'pasting', 'and', 'expansion', 'and', 'contraction', 'processes', 'are', 'utilized', 'in', 'the', 'paper', 'to', 'construct', 'new', 'partial', 'cubes', 'from', 'old', 'ones', 'in', 'particular', 'the', 'isometric', 'and', 'lattice', 'dimensions', 'of', 'finite', 'partial', 'cubes', 'obtained', 'by', 'means', 'of', 'these', 'operations', 'are', 'calculated']]\n",
      "[['a', 'fully', 'differential', 'calculation', 'in', 'perturbative', 'quantum', 'chromodynamic', 'be', 'present', 'for', 'the', 'production', 'of', 'massive', 'photon', 'pair', 'at', 'hadron', 'collider', 'all', 'next', 'to', 'lead', 'order', 'perturbative', 'contribution', 'from', 'quark', 'antiquark', 'gluon-(anti)quark', 'and', 'gluon', 'gluon', 'subprocesse', 'be', 'include', 'as', 'well', 'as', 'all', 'order', 'resummation', 'of', 'initial', 'state', 'gluon', 'radiation', 'valid', 'at', 'next', 'to', 'next', 'to', 'lead', 'logarithmic', 'accuracy', 'the', 'region', 'of', 'phase', 'space', 'be', 'specify', 'in', 'which', 'the', 'calculation', 'be', 'most', 'reliable', 'good', 'agreement', 'be', 'demonstrate', 'with', 'datum', 'from', 'the', 'Fermilab', 'Tevatron', 'and', 'prediction', 'be', 'make', 'for', 'more', 'detailed', 'test', 'with', 'CDF', 'and', 'do', 'datum', 'prediction', 'be', 'show', 'for', 'distribution', 'of', 'diphoton', 'pair', 'produce', 'at', 'the', 'energy', 'of', 'the', 'Large', 'Hadron', 'Collider', 'LHC', 'distribution', 'of', 'the', 'diphoton', 'pair', 'from', 'the', 'decay', 'of', 'a', 'Higgs', 'boson', 'be', 'contrast', 'with', 'those', 'produce', 'from', 'QCD', 'process', 'at', 'the', 'LHC', 'show', 'that', 'enhance', 'sensitivity', 'to', 'the', 'signal', 'can', 'be', 'obtain', 'with', 'judicious', 'selection', 'of', 'event'], ['we', 'describe', 'a', 'new', 'algorithm', 'the', '$', 'k,\\\\ell)$-pebble', 'game', 'with', 'color', 'and', 'use', 'it', 'obtain', 'a', 'characterization', 'of', 'the', 'family', 'of', '$', 'k,\\\\ell)$-sparse', 'graph', 'and', 'algorithmic', 'solution', 'to', 'a', 'family', 'of', 'problem', 'concern', 'tree', 'decomposition', 'of', 'graph', 'special', 'instance', 'of', 'sparse', 'graph', 'appear', 'in', 'rigidity', 'theory', 'and', 'have', 'receive', 'increase', 'attention', 'in', 'recent', 'year', 'in', 'particular', 'our', 'colored', 'pebble', 'generalize', 'and', 'strengthen', 'the', 'previous', 'result', 'of', 'Lee', 'and', 'Streinu', 'and', 'give', 'a', 'new', 'proof', 'of', 'the', 'Tutte', 'Nash', 'Williams', 'characterization', 'of', 'arboricity', 'we', 'also', 'present', 'a', 'new', 'decomposition', 'that', 'certify', 'sparsity', 'base', 'on', 'the', '$', 'k,\\\\ell)$-pebble', 'game', 'with', 'color', 'our', 'work', 'also', 'expose', 'connection', 'between', 'pebble', 'game', 'algorithm', 'and', 'previous', 'sparse', 'graph', 'algorithm', 'by', 'Gabow', 'Gabow', 'and', 'Westermann', 'and', 'Hendrickson'], ['the', 'evolution', 'of', 'Earth', 'Moon', 'system', 'be', 'describe', 'by', 'the', 'dark', 'matter', 'field', 'fluid', 'model', 'propose', 'in', 'the', 'Meeting', 'of', 'Division', 'of', 'Particle', 'and', 'Field', '2004', 'American', 'Physical', 'Society', 'the', 'current', 'behavior', 'of', 'the', 'Earth', 'Moon', 'system', 'agree', 'with', 'this', 'model', 'very', 'well', 'and', 'the', 'general', 'pattern', 'of', 'the', 'evolution', 'of', 'the', 'Moon', 'Earth', 'system', 'describe', 'by', 'this', 'model', 'agree', 'with', 'geological', 'and', 'fossil', 'evidence', 'the', 'close', 'distance', 'of', 'the', 'Moon', 'to', 'Earth', 'be', 'about', '259000', 'km', 'at', '4.5', 'billion', 'year', 'ago', 'which', 'be', 'far', 'beyond', 'the', 'Roche', \"'s\", 'limit', 'the', 'result', 'suggest', 'that', 'the', 'tidal', 'friction', 'may', 'not', 'be', 'the', 'primary', 'cause', 'for', 'the', 'evolution', 'of', 'the', 'Earth', 'Moon', 'system', 'the', 'average', 'dark', 'matter', 'field', 'fluid', 'constant', 'derive', 'from', 'Earth', 'Moon', 'system', 'datum', 'be', '4.39', 'x', '10^(-22', 's^(-1)m^(-1', 'this', 'model', 'predict', 'that', 'the', 'Mars', \"'s\", 'rotation', 'be', 'also', 'slow', 'with', 'the', 'angular', 'acceleration', 'rate', 'about', '-4.38', 'x', '10^(-22', 'rad', 's^(-2'], ['we', 'show', 'that', 'a', 'determinant', 'of', 'Stirling', 'cycle', 'number', 'count', 'unlabeled', 'acyclic', 'single', 'source', 'automata', 'the', 'proof', 'involve', 'a', 'bijection', 'from', 'these', 'automata', 'to', 'certain', 'marked', 'lattice', 'path', 'and', 'a', 'sign', 'reverse', 'involution', 'to', 'evaluate', 'the', 'determinant'], ['in', 'this', 'paper', 'we', 'show', 'how', 'to', 'compute', 'the', '$', '\\\\Lambda_{\\\\alpha}$', 'norm', '$', '\\\\alpha\\\\ge', '0', '$', 'use', 'the', 'dyadic', 'grid', 'this', 'result', 'be', 'a', 'consequence', 'of', 'the', 'description', 'of', 'the', 'Hardy', 'space', '$', 'h^p(r^n)$', 'in', 'term', 'of', 'dyadic', 'and', 'special', 'atom'], ['we', 'study', 'the', 'two', 'particle', 'wave', 'function', 'of', 'pair', 'atom', 'in', 'a', 'Fermi', 'gas', 'with', 'tunable', 'interaction', 'strength', 'control', 'by', 'Feshbach', 'resonance', 'the', 'Cooper', 'pair', 'wave', 'function', 'be', 'examine', 'for', 'its', 'bosonic', 'character', 'which', 'be', 'quantify', 'by', 'the', 'correction', 'of', 'Bose', 'enhancement', 'factor', 'associate', 'with', 'the', 'creation', 'and', 'annihilation', 'composite', 'particle', 'operator', 'an', 'example', 'be', 'give', 'for', 'a', 'three', 'dimensional', 'uniform', 'gas', 'two', 'definition', 'of', 'cooper', 'pair', 'wave', 'function', 'be', 'examine', 'one', 'of', 'which', 'be', 'choose', 'to', 'reflect', 'the', 'off', 'diagonal', 'long', 'range', 'order', 'ODLRO', 'another', 'one', 'correspond', 'to', 'a', 'pair', 'projection', 'of', 'a', 'BCS', 'state', 'on', 'the', 'side', 'with', 'negative', 'scatter', 'length', 'we', 'find', 'that', 'pair', 'atom', 'describe', 'by', 'ODLRO', 'be', 'more', 'bosonic', 'than', 'the', 'pair', 'project', 'definition', 'it', 'be', 'also', 'find', 'that', 'at', '$', 'k_f', 'a)^{-1', '\\\\ge', '1', '$', 'both', 'definition', 'give', 'similar', 'result', 'where', 'more', 'than', '90', 'of', 'the', 'atom', 'occupy', 'the', 'correspond', 'molecular', 'condensate'], ['a', 'rather', 'non', 'standard', 'quantum', 'representation', 'of', 'the', 'canonical', 'commutation', 'relation', 'of', 'quantum', 'mechanic', 'system', 'know', 'as', 'the', 'polymer', 'representation', 'have', 'gain', 'some', 'attention', 'in', 'recent', 'year', 'due', 'to', 'its', 'possible', 'relation', 'with', 'planck', 'scale', 'physic', 'in', 'particular', 'this', 'approach', 'have', 'be', 'follow', 'in', 'a', 'symmetric', 'sector', 'of', 'loop', 'quantum', 'gravity', 'know', 'as', 'loop', 'quantum', 'cosmology', 'here', 'we', 'explore', 'different', 'aspect', 'of', 'the', 'relation', 'between', 'the', 'ordinary', 'Schroedinger', 'theory', 'and', 'the', 'polymer', 'description', 'the', 'paper', 'have', 'two', 'part', 'in', 'the', 'first', 'one', 'we', 'derive', 'the', 'polymer', 'quantum', 'mechanic', 'start', 'from', 'the', 'ordinary', 'Schroedinger', 'theory', 'and', 'show', 'that', 'the', 'polymer', 'description', 'arise', 'as', 'an', 'appropriate', 'limit', 'in', 'the', 'second', 'part', 'we', 'consider', 'the', 'continuum', 'limit', 'of', 'this', 'theory', 'namely', 'the', 'reverse', 'process', 'in', 'which', 'one', 'start', 'from', 'the', 'discrete', 'theory', 'and', 'try', 'to', 'recover', 'back', 'the', 'ordinary', 'Schroedinger', 'quantum', 'mechanic', 'we', 'consider', 'several', 'example', 'of', 'interest', 'include', 'the', 'harmonic', 'oscillator', 'the', 'free', 'particle', 'and', 'a', 'simple', 'cosmological', 'model'], ['a', 'general', 'formulation', 'be', 'develop', 'to', 'represent', 'material', 'model', 'for', 'application', 'in', 'dynamic', 'loading', 'numerical', 'method', 'be', 'devise', 'to', 'calculate', 'response', 'to', 'shock', 'and', 'ramp', 'compression', 'and', 'ramp', 'decompression', 'generalize', 'previous', 'solution', 'for', 'scalar', 'equation', 'of', 'state', 'the', 'numerical', 'method', 'be', 'find', 'to', 'be', 'flexible', 'and', 'robust', 'and', 'match', 'analytic', 'result', 'to', 'a', 'high', 'accuracy', 'the', 'basic', 'ramp', 'and', 'shock', 'solution', 'method', 'be', 'couple', 'to', 'solve', 'for', 'composite', 'deformation', 'path', 'such', 'as', 'shock', 'induce', 'impact', 'and', 'shock', 'interaction', 'with', 'a', 'planar', 'interface', 'between', 'different', 'material', 'these', 'calculation', 'capture', 'much', 'of', 'the', 'physics', 'of', 'typical', 'material', 'dynamic', 'experiment', 'without', 'require', 'spatially', 'resolve', 'simulation', 'example', 'calculation', 'be', 'make', 'of', 'loading', 'history', 'in', 'metal', 'illustrate', 'the', 'effect', 'of', 'plastic', 'work', 'on', 'the', 'temperature', 'induce', 'in', 'quasi', 'isentropic', 'and', 'shock', 'release', 'experiment', 'and', 'the', 'effect', 'of', 'a', 'phase', 'transition'], ['we', 'discuss', 'the', 'result', 'from', 'the', 'combined', 'irac', 'and', 'MIPS', 'c2d', 'Spitzer', 'Legacy', 'observation', 'of', 'the', 'Serpens', 'star', 'form', 'region', 'in', 'particular', 'we', 'present', 'a', 'set', 'of', 'criterion', 'for', 'isolate', 'bona', 'fide', 'young', 'stellar', 'object', 'YSO', \"'s\", 'from', 'the', 'extensive', 'background', 'contamination', 'by', 'extra', 'galactic', 'object', 'we', 'then', 'discuss', 'the', 'property', 'of', 'the', 'result', 'high', 'confidence', 'set', 'of', 'YSO', \"'s\", 'we', 'find', '235', 'such', 'object', 'in', 'the', '0.85', 'deg^2', 'field', 'that', 'be', 'cover', 'with', 'both', 'irac', 'and', 'MIPS', 'an', 'additional', 'set', 'of', '51', 'low', 'confidence', 'YSO', \"'s\", 'outside', 'this', 'area', 'be', 'identify', 'from', 'the', 'MIPS', 'datum', 'combine', 'with', '2MASS', 'photometry', 'we', 'describe', 'two', 'set', 'of', 'result', 'color', 'color', 'diagram', 'to', 'compare', 'our', 'observe', 'source', 'property', 'with', 'those', 'of', 'theoretical', 'model', 'for', 'star', 'disk', 'envelope', 'system', 'and', 'our', 'own', 'modeling', 'of', 'the', 'subset', 'of', 'our', 'object', 'that', 'appear', 'to', 'be', 'star+disk', 'these', 'object', 'exhibit', 'a', 'very', 'wide', 'range', 'of', 'disk', 'property', 'from', 'many', 'that', 'can', 'be', 'fit', 'with', 'actively', 'accrete', 'disk', 'to', 'some', 'with', 'both', 'passive', 'disk', 'and', 'even', 'possibly', 'debris', 'disk', 'we', 'find', 'that', 'the', 'luminosity', 'function', 'of', 'YSO', \"'s\", 'in', 'Serpens', 'extend', 'down', 'to', 'at', 'least', 'a', 'few', 'x', '.001', 'Lsun', 'or', 'low', 'for', 'an', 'assumed', 'distance', 'of', '260', 'pc', 'the', 'low', 'limit', 'may', 'be', 'set', 'by', 'our', 'inability', 'to', 'distinguish', 'YSO', \"'s\", 'from', 'extra', 'galactic', 'source', 'more', 'than', 'by', 'the', 'lack', 'of', 'YSO', \"'s\", 'at', 'very', 'low', 'luminosity', 'a', 'spatial', 'clustering', 'analysis', 'show', 'that', 'the', 'nominally', 'less', 'evolve', 'YSO', \"'s\", 'be', 'more', 'highly', 'cluster', 'than', 'the', 'later', 'stage', 'and', 'that', 'the', 'background', 'extra', 'galactic', 'population', 'can', 'be', 'fit', 'by', 'the', 'same', 'two', 'point', 'correlation', 'function', 'as', 'see', 'in', 'other', 'extra', 'galactic', 'study', 'we', 'also', 'present', 'a', 'table', 'of', 'match', 'between', 'several', 'previous', 'infrared', 'and', 'x', 'ray', 'study', 'of', 'the', 'Serpens', 'YSO', 'population', 'and', 'our', 'Spitzer', 'datum', 'set'], ['partial', 'cube', 'be', 'isometric', 'subgraph', 'of', 'hypercube', 'structure', 'on', 'a', 'graph', 'define', 'by', 'mean', 'of', 'semicube', 'and', \"Djokovi\\\\'{c\", \"'s\", 'and', 'Winkler', \"'s\", 'relation', 'play', 'an', 'important', 'role', 'in', 'the', 'theory', 'of', 'partial', 'cube', 'these', 'structure', 'be', 'employ', 'in', 'the', 'paper', 'to', 'characterize', 'bipartite', 'graph', 'and', 'partial', 'cube', 'of', 'arbitrary', 'dimension', 'new', 'characterization', 'be', 'establish', 'and', 'new', 'proof', 'of', 'some', 'know', 'result', 'be', 'give', 'the', 'operation', 'of', 'cartesian', 'product', 'and', 'pasting', 'and', 'expansion', 'and', 'contraction', 'process', 'be', 'utilize', 'in', 'the', 'paper', 'to', 'construct', 'new', 'partial', 'cube', 'from', 'old', 'one', 'in', 'particular', 'the', 'isometric', 'and', 'lattice', 'dimension', 'of', 'finite', 'partial', 'cube', 'obtain', 'by', 'mean', 'of', 'these', 'operation', 'be', 'calculate']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_words_list = []\n",
    "lemm_list = []\n",
    "\n",
    "\n",
    "for index, row in df_short.iterrows():\n",
    "    text = row['abstract']\n",
    "    tokenized_words = tokenize_and_normalize(text)\n",
    "    lemm_words = lemm(text)\n",
    "    tokenized_words_list.append(tokenized_words)\n",
    "    lemm_list.append(lemm_words)\n",
    "\n",
    "\n",
    "print(tokenized_words_list)\n",
    "print(lemm_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'fully', 'differential', 'calculation', 'in', 'perturbative', 'quantum', 'chromodynamics', 'is', 'presented', 'for', 'the', 'production', 'of', 'massive', 'photon', 'pairs', 'at', 'hadron', 'colliders', 'all', 'next', 'to', 'leading', 'order', 'perturbative', 'contributions', 'from', 'quark', 'antiquark', 'gluon-(anti)quark', 'and', 'gluon', 'gluon', 'subprocesses', 'are', 'included', 'as', 'well', 'as', 'all', 'orders', 'resummation', 'of', 'initial', 'state', 'gluon', 'radiation', 'valid', 'at', 'next', 'to', 'next', 'to', 'leading', 'logarithmic', 'accuracy', 'the', 'region', 'of', 'phase', 'space', 'is', 'specified', 'in', 'which', 'the', 'calculation', 'is', 'most', 'reliable', 'good', 'agreement', 'is', 'demonstrated', 'with', 'data', 'from', 'the', 'fermilab', 'tevatron', 'and', 'predictions', 'are', 'made', 'for', 'more', 'detailed', 'tests', 'with', 'cdf', 'and', 'do', 'data', 'predictions', 'are', 'shown', 'for', 'distributions', 'of', 'diphoton', 'pairs', 'produced', 'at', 'the', 'energy', 'of', 'the', 'large', 'hadron', 'collider', 'lhc', 'distributions', 'of', 'the', 'diphoton', 'pairs', 'from', 'the', 'decay', 'of', 'a', 'higgs', 'boson', 'are', 'contrasted', 'with', 'those', 'produced', 'from', 'qcd', 'processes', 'at', 'the', 'lhc', 'showing', 'that', 'enhanced', 'sensitivity', 'to', 'the', 'signal', 'can', 'be', 'obtained', 'with', 'judicious', 'selection', 'of', 'events']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_words_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'fully', 'differential', 'calculation', 'in', 'perturbative', 'quantum', 'chromodynamic', 'be', 'present', 'for', 'the', 'production', 'of', 'massive', 'photon', 'pair', 'at', 'hadron', 'collider', 'all', 'next', 'to', 'lead', 'order', 'perturbative', 'contribution', 'from', 'quark', 'antiquark', 'gluon-(anti)quark', 'and', 'gluon', 'gluon', 'subprocesse', 'be', 'include', 'as', 'well', 'as', 'all', 'order', 'resummation', 'of', 'initial', 'state', 'gluon', 'radiation', 'valid', 'at', 'next', 'to', 'next', 'to', 'lead', 'logarithmic', 'accuracy', 'the', 'region', 'of', 'phase', 'space', 'be', 'specify', 'in', 'which', 'the', 'calculation', 'be', 'most', 'reliable', 'good', 'agreement', 'be', 'demonstrate', 'with', 'datum', 'from', 'the', 'Fermilab', 'Tevatron', 'and', 'prediction', 'be', 'make', 'for', 'more', 'detailed', 'test', 'with', 'CDF', 'and', 'do', 'datum', 'prediction', 'be', 'show', 'for', 'distribution', 'of', 'diphoton', 'pair', 'produce', 'at', 'the', 'energy', 'of', 'the', 'Large', 'Hadron', 'Collider', 'LHC', 'distribution', 'of', 'the', 'diphoton', 'pair', 'from', 'the', 'decay', 'of', 'a', 'Higgs', 'boson', 'be', 'contrast', 'with', 'those', 'produce', 'from', 'QCD', 'process', 'at', 'the', 'LHC', 'show', 'that', 'enhance', 'sensitivity', 'to', 'the', 'signal', 'can', 'be', 'obtain', 'with', 'judicious', 'selection', 'of', 'event', 'we', 'describe', 'a', 'new', 'algorithm', 'the', '$', 'k,\\\\ell)$-pebble', 'game', 'with', 'color', 'and', 'use', 'it', 'obtain', 'a', 'characterization', 'of', 'the', 'family', 'of', '$', 'k,\\\\ell)$-sparse', 'graph', 'and', 'algorithmic', 'solution', 'to', 'a', 'family', 'of', 'problem', 'concern', 'tree', 'decomposition', 'of', 'graph', 'special', 'instance', 'of', 'sparse', 'graph', 'appear', 'in', 'rigidity', 'theory', 'and', 'have', 'receive', 'increase', 'attention', 'in', 'recent', 'year', 'in', 'particular', 'our', 'colored', 'pebble', 'generalize', 'and', 'strengthen', 'the', 'previous', 'result', 'of', 'Lee', 'and', 'Streinu', 'and', 'give', 'a', 'new', 'proof', 'of', 'the', 'Tutte', 'Nash', 'Williams', 'characterization', 'of', 'arboricity', 'we', 'also', 'present', 'a', 'new', 'decomposition', 'that', 'certify', 'sparsity', 'base', 'on', 'the', '$', 'k,\\\\ell)$-pebble', 'game', 'with', 'color', 'our', 'work', 'also', 'expose', 'connection', 'between', 'pebble', 'game', 'algorithm', 'and', 'previous', 'sparse', 'graph', 'algorithm', 'by', 'Gabow', 'Gabow', 'and', 'Westermann', 'and', 'Hendrickson', 'the', 'evolution', 'of', 'Earth', 'Moon', 'system', 'be', 'describe', 'by', 'the', 'dark', 'matter', 'field', 'fluid', 'model', 'propose', 'in', 'the', 'Meeting', 'of', 'Division', 'of', 'Particle', 'and', 'Field', '2004', 'American', 'Physical', 'Society', 'the', 'current', 'behavior', 'of', 'the', 'Earth', 'Moon', 'system', 'agree', 'with', 'this', 'model', 'very', 'well', 'and', 'the', 'general', 'pattern', 'of', 'the', 'evolution', 'of', 'the', 'Moon', 'Earth', 'system', 'describe', 'by', 'this', 'model', 'agree', 'with', 'geological', 'and', 'fossil', 'evidence', 'the', 'close', 'distance', 'of', 'the', 'Moon', 'to', 'Earth', 'be', 'about', '259000', 'km', 'at', '4.5', 'billion', 'year', 'ago', 'which', 'be', 'far', 'beyond', 'the', 'Roche', \"'s\", 'limit', 'the', 'result', 'suggest', 'that', 'the', 'tidal', 'friction', 'may', 'not', 'be', 'the', 'primary', 'cause', 'for', 'the', 'evolution', 'of', 'the', 'Earth', 'Moon', 'system', 'the', 'average', 'dark', 'matter', 'field', 'fluid', 'constant', 'derive', 'from', 'Earth', 'Moon', 'system', 'datum', 'be', '4.39', 'x', '10^(-22', 's^(-1)m^(-1', 'this', 'model', 'predict', 'that', 'the', 'Mars', \"'s\", 'rotation', 'be', 'also', 'slow', 'with', 'the', 'angular', 'acceleration', 'rate', 'about', '-4.38', 'x', '10^(-22', 'rad', 's^(-2', 'we', 'show', 'that', 'a', 'determinant', 'of', 'Stirling', 'cycle', 'number', 'count', 'unlabeled', 'acyclic', 'single', 'source', 'automata', 'the', 'proof', 'involve', 'a', 'bijection', 'from', 'these', 'automata', 'to', 'certain', 'marked', 'lattice', 'path', 'and', 'a', 'sign', 'reverse', 'involution', 'to', 'evaluate', 'the', 'determinant', 'in', 'this', 'paper', 'we', 'show', 'how', 'to', 'compute', 'the', '$', '\\\\Lambda_{\\\\alpha}$', 'norm', '$', '\\\\alpha\\\\ge', '0', '$', 'use', 'the', 'dyadic', 'grid', 'this', 'result', 'be', 'a', 'consequence', 'of', 'the', 'description', 'of', 'the', 'Hardy', 'space', '$', 'h^p(r^n)$', 'in', 'term', 'of', 'dyadic', 'and', 'special', 'atom', 'we', 'study', 'the', 'two', 'particle', 'wave', 'function', 'of', 'pair', 'atom', 'in', 'a', 'Fermi', 'gas', 'with', 'tunable', 'interaction', 'strength', 'control', 'by', 'Feshbach', 'resonance', 'the', 'Cooper', 'pair', 'wave', 'function', 'be', 'examine', 'for', 'its', 'bosonic', 'character', 'which', 'be', 'quantify', 'by', 'the', 'correction', 'of', 'Bose', 'enhancement', 'factor', 'associate', 'with', 'the', 'creation', 'and', 'annihilation', 'composite', 'particle', 'operator', 'an', 'example', 'be', 'give', 'for', 'a', 'three', 'dimensional', 'uniform', 'gas', 'two', 'definition', 'of', 'cooper', 'pair', 'wave', 'function', 'be', 'examine', 'one', 'of', 'which', 'be', 'choose', 'to', 'reflect', 'the', 'off', 'diagonal', 'long', 'range', 'order', 'ODLRO', 'another', 'one', 'correspond', 'to', 'a', 'pair', 'projection', 'of', 'a', 'BCS', 'state', 'on', 'the', 'side', 'with', 'negative', 'scatter', 'length', 'we', 'find', 'that', 'pair', 'atom', 'describe', 'by', 'ODLRO', 'be', 'more', 'bosonic', 'than', 'the', 'pair', 'project', 'definition', 'it', 'be', 'also', 'find', 'that', 'at', '$', 'k_f', 'a)^{-1', '\\\\ge', '1', '$', 'both', 'definition', 'give', 'similar', 'result', 'where', 'more', 'than', '90', 'of', 'the', 'atom', 'occupy', 'the', 'correspond', 'molecular', 'condensate', 'a', 'rather', 'non', 'standard', 'quantum', 'representation', 'of', 'the', 'canonical', 'commutation', 'relation', 'of', 'quantum', 'mechanic', 'system', 'know', 'as', 'the', 'polymer', 'representation', 'have', 'gain', 'some', 'attention', 'in', 'recent', 'year', 'due', 'to', 'its', 'possible', 'relation', 'with', 'planck', 'scale', 'physic', 'in', 'particular', 'this', 'approach', 'have', 'be', 'follow', 'in', 'a', 'symmetric', 'sector', 'of', 'loop', 'quantum', 'gravity', 'know', 'as', 'loop', 'quantum', 'cosmology', 'here', 'we', 'explore', 'different', 'aspect', 'of', 'the', 'relation', 'between', 'the', 'ordinary', 'Schroedinger', 'theory', 'and', 'the', 'polymer', 'description', 'the', 'paper', 'have', 'two', 'part', 'in', 'the', 'first', 'one', 'we', 'derive', 'the', 'polymer', 'quantum', 'mechanic', 'start', 'from', 'the', 'ordinary', 'Schroedinger', 'theory', 'and', 'show', 'that', 'the', 'polymer', 'description', 'arise', 'as', 'an', 'appropriate', 'limit', 'in', 'the', 'second', 'part', 'we', 'consider', 'the', 'continuum', 'limit', 'of', 'this', 'theory', 'namely', 'the', 'reverse', 'process', 'in', 'which', 'one', 'start', 'from', 'the', 'discrete', 'theory', 'and', 'try', 'to', 'recover', 'back', 'the', 'ordinary', 'Schroedinger', 'quantum', 'mechanic', 'we', 'consider', 'several', 'example', 'of', 'interest', 'include', 'the', 'harmonic', 'oscillator', 'the', 'free', 'particle', 'and', 'a', 'simple', 'cosmological', 'model', 'a', 'general', 'formulation', 'be', 'develop', 'to', 'represent', 'material', 'model', 'for', 'application', 'in', 'dynamic', 'loading', 'numerical', 'method', 'be', 'devise', 'to', 'calculate', 'response', 'to', 'shock', 'and', 'ramp', 'compression', 'and', 'ramp', 'decompression', 'generalize', 'previous', 'solution', 'for', 'scalar', 'equation', 'of', 'state', 'the', 'numerical', 'method', 'be', 'find', 'to', 'be', 'flexible', 'and', 'robust', 'and', 'match', 'analytic', 'result', 'to', 'a', 'high', 'accuracy', 'the', 'basic', 'ramp', 'and', 'shock', 'solution', 'method', 'be', 'couple', 'to', 'solve', 'for', 'composite', 'deformation', 'path', 'such', 'as', 'shock', 'induce', 'impact', 'and', 'shock', 'interaction', 'with', 'a', 'planar', 'interface', 'between', 'different', 'material', 'these', 'calculation', 'capture', 'much', 'of', 'the', 'physics', 'of', 'typical', 'material', 'dynamic', 'experiment', 'without', 'require', 'spatially', 'resolve', 'simulation', 'example', 'calculation', 'be', 'make', 'of', 'loading', 'history', 'in', 'metal', 'illustrate', 'the', 'effect', 'of', 'plastic', 'work', 'on', 'the', 'temperature', 'induce', 'in', 'quasi', 'isentropic', 'and', 'shock', 'release', 'experiment', 'and', 'the', 'effect', 'of', 'a', 'phase', 'transition', 'we', 'discuss', 'the', 'result', 'from', 'the', 'combined', 'irac', 'and', 'MIPS', 'c2d', 'Spitzer', 'Legacy', 'observation', 'of', 'the', 'Serpens', 'star', 'form', 'region', 'in', 'particular', 'we', 'present', 'a', 'set', 'of', 'criterion', 'for', 'isolate', 'bona', 'fide', 'young', 'stellar', 'object', 'YSO', \"'s\", 'from', 'the', 'extensive', 'background', 'contamination', 'by', 'extra', 'galactic', 'object', 'we', 'then', 'discuss', 'the', 'property', 'of', 'the', 'result', 'high', 'confidence', 'set', 'of', 'YSO', \"'s\", 'we', 'find', '235', 'such', 'object', 'in', 'the', '0.85', 'deg^2', 'field', 'that', 'be', 'cover', 'with', 'both', 'irac', 'and', 'MIPS', 'an', 'additional', 'set', 'of', '51', 'low', 'confidence', 'YSO', \"'s\", 'outside', 'this', 'area', 'be', 'identify', 'from', 'the', 'MIPS', 'datum', 'combine', 'with', '2MASS', 'photometry', 'we', 'describe', 'two', 'set', 'of', 'result', 'color', 'color', 'diagram', 'to', 'compare', 'our', 'observe', 'source', 'property', 'with', 'those', 'of', 'theoretical', 'model', 'for', 'star', 'disk', 'envelope', 'system', 'and', 'our', 'own', 'modeling', 'of', 'the', 'subset', 'of', 'our', 'object', 'that', 'appear', 'to', 'be', 'star+disk', 'these', 'object', 'exhibit', 'a', 'very', 'wide', 'range', 'of', 'disk', 'property', 'from', 'many', 'that', 'can', 'be', 'fit', 'with', 'actively', 'accrete', 'disk', 'to', 'some', 'with', 'both', 'passive', 'disk', 'and', 'even', 'possibly', 'debris', 'disk', 'we', 'find', 'that', 'the', 'luminosity', 'function', 'of', 'YSO', \"'s\", 'in', 'Serpens', 'extend', 'down', 'to', 'at', 'least', 'a', 'few', 'x', '.001', 'Lsun', 'or', 'low', 'for', 'an', 'assumed', 'distance', 'of', '260', 'pc', 'the', 'low', 'limit', 'may', 'be', 'set', 'by', 'our', 'inability', 'to', 'distinguish', 'YSO', \"'s\", 'from', 'extra', 'galactic', 'source', 'more', 'than', 'by', 'the', 'lack', 'of', 'YSO', \"'s\", 'at', 'very', 'low', 'luminosity', 'a', 'spatial', 'clustering', 'analysis', 'show', 'that', 'the', 'nominally', 'less', 'evolve', 'YSO', \"'s\", 'be', 'more', 'highly', 'cluster', 'than', 'the', 'later', 'stage', 'and', 'that', 'the', 'background', 'extra', 'galactic', 'population', 'can', 'be', 'fit', 'by', 'the', 'same', 'two', 'point', 'correlation', 'function', 'as', 'see', 'in', 'other', 'extra', 'galactic', 'study', 'we', 'also', 'present', 'a', 'table', 'of', 'match', 'between', 'several', 'previous', 'infrared', 'and', 'x', 'ray', 'study', 'of', 'the', 'Serpens', 'YSO', 'population', 'and', 'our', 'Spitzer', 'datum', 'set', 'partial', 'cube', 'be', 'isometric', 'subgraph', 'of', 'hypercube', 'structure', 'on', 'a', 'graph', 'define', 'by', 'mean', 'of', 'semicube', 'and', \"Djokovi\\\\'{c\", \"'s\", 'and', 'Winkler', \"'s\", 'relation', 'play', 'an', 'important', 'role', 'in', 'the', 'theory', 'of', 'partial', 'cube', 'these', 'structure', 'be', 'employ', 'in', 'the', 'paper', 'to', 'characterize', 'bipartite', 'graph', 'and', 'partial', 'cube', 'of', 'arbitrary', 'dimension', 'new', 'characterization', 'be', 'establish', 'and', 'new', 'proof', 'of', 'some', 'know', 'result', 'be', 'give', 'the', 'operation', 'of', 'cartesian', 'product', 'and', 'pasting', 'and', 'expansion', 'and', 'contraction', 'process', 'be', 'utilize', 'in', 'the', 'paper', 'to', 'construct', 'new', 'partial', 'cube', 'from', 'old', 'one', 'in', 'particular', 'the', 'isometric', 'and', 'lattice', 'dimension', 'of', 'finite', 'partial', 'cube', 'obtain', 'by', 'mean', 'of', 'these', 'operation', 'be', 'calculate']\n"
     ]
    }
   ],
   "source": [
    "# create list with evey word\n",
    "words = [word for sublist in lemm_list for word in sublist]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with all words without duplicates\n",
    "words_list = []\n",
    "for i in range(len(words)):\n",
    "    if words[i] not in words_list:\n",
    "        words_list.append(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'fully', 'differential', 'calculation', 'in', 'perturbative', 'quantum', 'chromodynamic', 'be', 'present', 'for', 'the', 'production', 'of', 'massive', 'photon', 'pair', 'at', 'hadron', 'collider', 'all', 'next', 'to', 'lead', 'order', 'contribution', 'from', 'quark', 'antiquark', 'gluon-(anti)quark', 'and', 'gluon', 'subprocesse', 'include', 'as', 'well', 'resummation', 'initial', 'state', 'radiation', 'valid', 'logarithmic', 'accuracy', 'region', 'phase', 'space', 'specify', 'which', 'most', 'reliable', 'good', 'agreement', 'demonstrate', 'with', 'datum', 'Fermilab', 'Tevatron', 'prediction', 'make', 'more', 'detailed', 'test', 'CDF', 'do', 'show', 'distribution', 'diphoton', 'produce', 'energy', 'Large', 'Hadron', 'Collider', 'LHC', 'decay', 'Higgs', 'boson', 'contrast', 'those', 'QCD', 'process', 'that', 'enhance', 'sensitivity', 'signal', 'can', 'obtain', 'judicious', 'selection', 'event', 'we', 'describe', 'new', 'algorithm', '$', 'k,\\\\ell)$-pebble', 'game', 'color', 'use', 'it', 'characterization', 'family', 'k,\\\\ell)$-sparse', 'graph', 'algorithmic', 'solution', 'problem', 'concern', 'tree', 'decomposition', 'special', 'instance', 'sparse', 'appear', 'rigidity', 'theory', 'have', 'receive', 'increase', 'attention', 'recent', 'year', 'particular', 'our', 'colored', 'pebble', 'generalize', 'strengthen', 'previous', 'result', 'Lee', 'Streinu', 'give', 'proof', 'Tutte', 'Nash', 'Williams', 'arboricity', 'also', 'certify', 'sparsity', 'base', 'on', 'work', 'expose', 'connection', 'between', 'by', 'Gabow', 'Westermann', 'Hendrickson', 'evolution', 'Earth', 'Moon', 'system', 'dark', 'matter', 'field', 'fluid', 'model', 'propose', 'Meeting', 'Division', 'Particle', 'Field', '2004', 'American', 'Physical', 'Society', 'current', 'behavior', 'agree', 'this', 'very', 'general', 'pattern', 'geological', 'fossil', 'evidence', 'close', 'distance', 'about', '259000', 'km', '4.5', 'billion', 'ago', 'far', 'beyond', 'Roche', \"'s\", 'limit', 'suggest', 'tidal', 'friction', 'may', 'not', 'primary', 'cause', 'average', 'constant', 'derive', '4.39', 'x', '10^(-22', 's^(-1)m^(-1', 'predict', 'Mars', 'rotation', 'slow', 'angular', 'acceleration', 'rate', '-4.38', 'rad', 's^(-2', 'determinant', 'Stirling', 'cycle', 'number', 'count', 'unlabeled', 'acyclic', 'single', 'source', 'automata', 'involve', 'bijection', 'these', 'certain', 'marked', 'lattice', 'path', 'sign', 'reverse', 'involution', 'evaluate', 'paper', 'how', 'compute', '\\\\Lambda_{\\\\alpha}$', 'norm', '\\\\alpha\\\\ge', '0', 'dyadic', 'grid', 'consequence', 'description', 'Hardy', 'h^p(r^n)$', 'term', 'atom', 'study', 'two', 'particle', 'wave', 'function', 'Fermi', 'gas', 'tunable', 'interaction', 'strength', 'control', 'Feshbach', 'resonance', 'Cooper', 'examine', 'its', 'bosonic', 'character', 'quantify', 'correction', 'Bose', 'enhancement', 'factor', 'associate', 'creation', 'annihilation', 'composite', 'operator', 'an', 'example', 'three', 'dimensional', 'uniform', 'definition', 'cooper', 'one', 'choose', 'reflect', 'off', 'diagonal', 'long', 'range', 'ODLRO', 'another', 'correspond', 'projection', 'BCS', 'side', 'negative', 'scatter', 'length', 'find', 'than', 'project', 'k_f', 'a)^{-1', '\\\\ge', '1', 'both', 'similar', 'where', '90', 'occupy', 'molecular', 'condensate', 'rather', 'non', 'standard', 'representation', 'canonical', 'commutation', 'relation', 'mechanic', 'know', 'polymer', 'gain', 'some', 'due', 'possible', 'planck', 'scale', 'physic', 'approach', 'follow', 'symmetric', 'sector', 'loop', 'gravity', 'cosmology', 'here', 'explore', 'different', 'aspect', 'ordinary', 'Schroedinger', 'part', 'first', 'start', 'arise', 'appropriate', 'second', 'consider', 'continuum', 'namely', 'discrete', 'try', 'recover', 'back', 'several', 'interest', 'harmonic', 'oscillator', 'free', 'simple', 'cosmological', 'formulation', 'develop', 'represent', 'material', 'application', 'dynamic', 'loading', 'numerical', 'method', 'devise', 'calculate', 'response', 'shock', 'ramp', 'compression', 'decompression', 'scalar', 'equation', 'flexible', 'robust', 'match', 'analytic', 'high', 'basic', 'couple', 'solve', 'deformation', 'such', 'induce', 'impact', 'planar', 'interface', 'capture', 'much', 'physics', 'typical', 'experiment', 'without', 'require', 'spatially', 'resolve', 'simulation', 'history', 'metal', 'illustrate', 'effect', 'plastic', 'temperature', 'quasi', 'isentropic', 'release', 'transition', 'discuss', 'combined', 'irac', 'MIPS', 'c2d', 'Spitzer', 'Legacy', 'observation', 'Serpens', 'star', 'form', 'set', 'criterion', 'isolate', 'bona', 'fide', 'young', 'stellar', 'object', 'YSO', 'extensive', 'background', 'contamination', 'extra', 'galactic', 'then', 'property', 'confidence', '235', '0.85', 'deg^2', 'cover', 'additional', '51', 'low', 'outside', 'area', 'identify', 'combine', '2MASS', 'photometry', 'diagram', 'compare', 'observe', 'theoretical', 'disk', 'envelope', 'own', 'modeling', 'subset', 'star+disk', 'exhibit', 'wide', 'many', 'fit', 'actively', 'accrete', 'passive', 'even', 'possibly', 'debris', 'luminosity', 'extend', 'down', 'least', 'few', '.001', 'Lsun', 'or', 'assumed', '260', 'pc', 'inability', 'distinguish', 'lack', 'spatial', 'clustering', 'analysis', 'nominally', 'less', 'evolve', 'highly', 'cluster', 'later', 'stage', 'population', 'same', 'point', 'correlation', 'see', 'other', 'table', 'infrared', 'ray', 'partial', 'cube', 'isometric', 'subgraph', 'hypercube', 'structure', 'define', 'mean', 'semicube', \"Djokovi\\\\'{c\", 'Winkler', 'play', 'important', 'role', 'employ', 'characterize', 'bipartite', 'arbitrary', 'dimension', 'establish', 'operation', 'cartesian', 'product', 'pasting', 'expansion', 'contraction', 'utilize', 'construct', 'old', 'finite']\n"
     ]
    }
   ],
   "source": [
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "120\n",
      "151\n",
      "37\n",
      "41\n",
      "148\n",
      "157\n",
      "135\n",
      "299\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    a = len(tokenized_words_list[i])\n",
    "    print(a)\n",
    "# mit der Anzahl von Wörtern im Abstract könnte man zuordnen, welche Wörter zu welcher Arbeit gehören\n",
    "# z.B. Wörter 0 bis 149 gehören zu paper1\n",
    "# was machen mit gleichen Wörtern in mehreren Arbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a fully differential calculation in perturbative quantum chromodynamic be present for the production of massive photon pair at hadron collider all next to lead order perturbative contribution from quark antiquark gluon-(anti)quark and gluon gluon subprocesse be include as well as all order resummation of initial state gluon radiation valid at next to next to lead logarithmic accuracy the region of phase space be specify in which the calculation be most reliable good agreement be demonstrate with datum from the Fermilab Tevatron and prediction be make for more detailed test with CDF and do datum prediction be show for distribution of diphoton pair produce at the energy of the Large Hadron Collider LHC distribution of the diphoton pair from the decay of a Higgs boson be contrast with those produce from QCD process at the LHC show that enhance sensitivity to the signal can be obtain with judicious selection of event', 'we describe a new algorithm the $ k,\\\\ell)$-pebble game with color and use it obtain a characterization of the family of $ k,\\\\ell)$-sparse graph and algorithmic solution to a family of problem concern tree decomposition of graph special instance of sparse graph appear in rigidity theory and have receive increase attention in recent year in particular our colored pebble generalize and strengthen the previous result of Lee and Streinu and give a new proof of the Tutte Nash Williams characterization of arboricity we also present a new decomposition that certify sparsity base on the $ k,\\\\ell)$-pebble game with color our work also expose connection between pebble game algorithm and previous sparse graph algorithm by Gabow Gabow and Westermann and Hendrickson', \"the evolution of Earth Moon system be describe by the dark matter field fluid model propose in the Meeting of Division of Particle and Field 2004 American Physical Society the current behavior of the Earth Moon system agree with this model very well and the general pattern of the evolution of the Moon Earth system describe by this model agree with geological and fossil evidence the close distance of the Moon to Earth be about 259000 km at 4.5 billion year ago which be far beyond the Roche 's limit the result suggest that the tidal friction may not be the primary cause for the evolution of the Earth Moon system the average dark matter field fluid constant derive from Earth Moon system datum be 4.39 x 10^(-22 s^(-1)m^(-1 this model predict that the Mars 's rotation be also slow with the angular acceleration rate about -4.38 x 10^(-22 rad s^(-2\", 'we show that a determinant of Stirling cycle number count unlabeled acyclic single source automata the proof involve a bijection from these automata to certain marked lattice path and a sign reverse involution to evaluate the determinant', 'in this paper we show how to compute the $ \\\\Lambda_{\\\\alpha}$ norm $ \\\\alpha\\\\ge 0 $ use the dyadic grid this result be a consequence of the description of the Hardy space $ h^p(r^n)$ in term of dyadic and special atom', 'we study the two particle wave function of pair atom in a Fermi gas with tunable interaction strength control by Feshbach resonance the Cooper pair wave function be examine for its bosonic character which be quantify by the correction of Bose enhancement factor associate with the creation and annihilation composite particle operator an example be give for a three dimensional uniform gas two definition of cooper pair wave function be examine one of which be choose to reflect the off diagonal long range order ODLRO another one correspond to a pair projection of a BCS state on the side with negative scatter length we find that pair atom describe by ODLRO be more bosonic than the pair project definition it be also find that at $ k_f a)^{-1 \\\\ge 1 $ both definition give similar result where more than 90 of the atom occupy the correspond molecular condensate', 'a rather non standard quantum representation of the canonical commutation relation of quantum mechanic system know as the polymer representation have gain some attention in recent year due to its possible relation with planck scale physic in particular this approach have be follow in a symmetric sector of loop quantum gravity know as loop quantum cosmology here we explore different aspect of the relation between the ordinary Schroedinger theory and the polymer description the paper have two part in the first one we derive the polymer quantum mechanic start from the ordinary Schroedinger theory and show that the polymer description arise as an appropriate limit in the second part we consider the continuum limit of this theory namely the reverse process in which one start from the discrete theory and try to recover back the ordinary Schroedinger quantum mechanic we consider several example of interest include the harmonic oscillator the free particle and a simple cosmological model', 'a general formulation be develop to represent material model for application in dynamic loading numerical method be devise to calculate response to shock and ramp compression and ramp decompression generalize previous solution for scalar equation of state the numerical method be find to be flexible and robust and match analytic result to a high accuracy the basic ramp and shock solution method be couple to solve for composite deformation path such as shock induce impact and shock interaction with a planar interface between different material these calculation capture much of the physics of typical material dynamic experiment without require spatially resolve simulation example calculation be make of loading history in metal illustrate the effect of plastic work on the temperature induce in quasi isentropic and shock release experiment and the effect of a phase transition', \"we discuss the result from the combined irac and MIPS c2d Spitzer Legacy observation of the Serpens star form region in particular we present a set of criterion for isolate bona fide young stellar object YSO 's from the extensive background contamination by extra galactic object we then discuss the property of the result high confidence set of YSO 's we find 235 such object in the 0.85 deg^2 field that be cover with both irac and MIPS an additional set of 51 low confidence YSO 's outside this area be identify from the MIPS datum combine with 2MASS photometry we describe two set of result color color diagram to compare our observe source property with those of theoretical model for star disk envelope system and our own modeling of the subset of our object that appear to be star+disk these object exhibit a very wide range of disk property from many that can be fit with actively accrete disk to some with both passive disk and even possibly debris disk we find that the luminosity function of YSO 's in Serpens extend down to at least a few x .001 Lsun or low for an assumed distance of 260 pc the low limit may be set by our inability to distinguish YSO 's from extra galactic source more than by the lack of YSO 's at very low luminosity a spatial clustering analysis show that the nominally less evolve YSO 's be more highly cluster than the later stage and that the background extra galactic population can be fit by the same two point correlation function as see in other extra galactic study we also present a table of match between several previous infrared and x ray study of the Serpens YSO population and our Spitzer datum set\", \"partial cube be isometric subgraph of hypercube structure on a graph define by mean of semicube and Djokovi\\\\'{c 's and Winkler 's relation play an important role in the theory of partial cube these structure be employ in the paper to characterize bipartite graph and partial cube of arbitrary dimension new characterization be establish and new proof of some know result be give the operation of cartesian product and pasting and expansion and contraction process be utilize in the paper to construct new partial cube from old one in particular the isometric and lattice dimension of finite partial cube obtain by mean of these operation be calculate\"]\n"
     ]
    }
   ],
   "source": [
    "text_list = [' '.join(words) for words in lemm_list]\n",
    "\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with titles\n",
    "# title_list=[]\n",
    "# for i in range(len(df_short)):\n",
    "#     title_list.append(df_short.title[i])\n",
    "# print(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists of attributes \n",
    "\n",
    "licenses_list = []\n",
    "def licenses_in_list(df):\n",
    "    for i in range(len(df)):\n",
    "        licenses_list.append(df.license[i])\n",
    "    print(licenses_list)\n",
    "\n",
    "doi_list = []\n",
    "def doi_in_list(df):\n",
    "    for i in range(len(df)):\n",
    "        doi_list.append(df.doi[i])\n",
    "    print(doi_list)\n",
    "\n",
    "title_list = []\n",
    "def titles_in_list(df):\n",
    "    for i in range(len(df)):\n",
    "        title_list.append(df.title[i])\n",
    "    print(title_list)\n",
    "\n",
    "comment_list = []\n",
    "def comments_in_list(df):\n",
    "    for i in range(len(df)):\n",
    "        comment_list.append(df.comments[i])\n",
    "    print(comment_list)\n",
    "\n",
    "\n",
    "author_list = []\n",
    "def authors_in_list(df):\n",
    "    for i in range(len(df)):\n",
    "        author_list.append(df.authors_parsed[i])\n",
    "    print(author_list)\n",
    "\n",
    "\n",
    "categories_list = []\n",
    "def categories_in_list(df):\n",
    "    for i in range(len(df)):\n",
    "        categories_list.append(df['categories'][i])\n",
    "    print(categories_list)\n",
    "\n",
    "\n",
    "journal_list = []\n",
    "def journals_in_list(df):\n",
    "    for i in range(len(df)):\n",
    "        journal_list.append(df['journal-ref'][i])\n",
    "    print(journal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', nan, nan, nan, nan, nan, 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', nan, nan]\n",
      "['10.1103/PhysRevD.76.013009', nan, nan, nan, nan, '10.1103/PhysRevA.75.043613', '10.1103/PhysRevD.76.044016', '10.1063/1.2975338', '10.1086/518646', nan]\n",
      "['Calculation of prompt diphoton production cross sections at Tevatron and\\r\\n  LHC energies', 'Sparsity-certifying Graph Decompositions', 'The evolution of the Earth-Moon system based on the dark matter field\\r\\n  fluid model', 'A determinant of Stirling cycle numbers counts unlabeled acyclic\\r\\n  single-source automata', 'From dyadic $\\\\Lambda_{\\\\alpha}$ to $\\\\Lambda_{\\\\alpha}$', 'Bosonic characters of atomic Cooper pairs across resonance', 'Polymer Quantum Mechanics and its Continuum Limit', 'Numerical solution of shock and ramp compression for general material\\r\\n  properties', 'The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The\\r\\n  Serpens YSO Population As Observed With IRAC and MIPS', 'Partial cubes: structures, characterizations, and constructions']\n",
      "['37 pages, 15 figures; published version', 'To appear in Graphs and Combinatorics', '23 pages, 3 figures', '11 pages', nan, '6 pages, 4 figures, accepted by PRA', '16 pages, no figures. Typos corrected to match published version', 'Minor corrections', nan, '36 pages, 17 figures']\n",
      "[['Balázs C.', 'Berger E. L.', 'Nadolsky P. M.', 'Yuan C. -P.'], ['Streinu Ileana', 'Theran Louis'], ['Pan Hongjun'], ['Callan David'], ['Abu-Shammala Wael', 'Torchinsky Alberto'], ['Pong Y. H.', 'Law C. K.'], ['Corichi Alejandro', 'Vukasinac Tatjana', 'Zapata Jose A.'], ['Swift Damian C.'], ['Harvey Paul', 'Merin Bruno', 'Huard Tracy L.', 'Rebull Luisa M.', 'Chapman Nicholas', 'Evans Neal J. II', 'Myers Philip C.'], ['Ovchinnikov Sergei']]\n",
      "[['hep-ph'], ['math.CO', 'cs.CG'], ['physics.gen-ph'], ['math.CO'], ['math.CA', 'math.FA'], ['cond-mat.mes-hall'], ['gr-qc'], ['cond-mat.mtrl-sci'], ['astro-ph'], ['math.CO']]\n",
      "['Phys.Rev.D76:013009,2007', nan, nan, nan, 'Illinois J. Math. 52 (2008) no.2, 681-689', nan, 'Phys.Rev.D76:044016,2007', 'Journal of Applied Physics, vol 104, 073536 (2008)', 'Astrophys.J.663:1149-1173,2007', nan]\n"
     ]
    }
   ],
   "source": [
    "licenses_in_list(df_short)\n",
    "doi_in_list(df_short)\n",
    "titles_in_list(df_short)\n",
    "comments_in_list(df_short)\n",
    "authors_in_list(df_short)\n",
    "categories_in_list(df_short)\n",
    "journals_in_list(df_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    num_nodes=10,\n",
       "    license=[10],\n",
       "    doi=[10],\n",
       "    title=[10],\n",
       "    comment=[10],\n",
       "  },\n",
       "  author={\n",
       "    num_nodes=10,\n",
       "    name=[10],\n",
       "  },\n",
       "  category={\n",
       "    num_nodes=10,\n",
       "    name=[10],\n",
       "  },\n",
       "  journal={\n",
       "    num_nodes=10,\n",
       "    name=[10],\n",
       "  },\n",
       "  word={\n",
       "    num_nodes=542,\n",
       "    name=[542],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = HeteroData()\n",
    "data['paper'].num_nodes = len(df_short)\n",
    "data['paper'].license = licenses_list\n",
    "data['paper'].doi = doi_list\n",
    "data['paper'].title = title_list\n",
    "data['paper'].comment = comment_list\n",
    "\n",
    "data['author'].num_nodes = len(df_short)\n",
    "data['author'].name = author_list\n",
    "\n",
    "data['category'].num_nodes = len(df_short)\n",
    "data['category'].name = categories_list\n",
    "\n",
    "data['journal'].num_nodes = len(df_short)\n",
    "data['journal'].name = journal_list\n",
    "\n",
    "data['word'].num_nodes = len(words_list)\n",
    "data['word'].name = words_list\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNpapersearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
