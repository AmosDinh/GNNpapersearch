{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    num_nodes=2,\n",
       "    license=[2],\n",
       "    doi=[2],\n",
       "    title=[2],\n",
       "    comment=[2],\n",
       "  },\n",
       "  author={\n",
       "    num_nodes=3,\n",
       "    name=[3],\n",
       "  },\n",
       "  category={\n",
       "    num_nodes=4,\n",
       "    name=[4],\n",
       "  },\n",
       "  journal={\n",
       "    num_nodes=4,\n",
       "    name=[4],\n",
       "  },\n",
       "  word={\n",
       "    num_nodes=5,\n",
       "    name=[5],\n",
       "  },\n",
       "  (paper, written_by, author)={ edge_index=[2, 2] },\n",
       "  (paper, has_category, category)={ edge_index=[2, 2] },\n",
       "  (paper, in_journal, journal)={ edge_index=[2, 2] },\n",
       "  (paper, has_word, word)={\n",
       "    edge_index=[2, 2],\n",
       "    edge_attr=[2, 1],\n",
       "  },\n",
       "  (paper, has_titleword, word)={ edge_index=[2, 2] },\n",
       "  (word, cooccurs_with, word)={\n",
       "    edge_index=[2, 2],\n",
       "    edge_attr=[2, 1],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch \n",
    "data = HeteroData()\n",
    "\n",
    "data['paper'].num_nodes = 2\n",
    "data['paper'].license = ['llicensepaper1', 'licensepaper2']\n",
    "data['paper'].doi = ['doi123', None]\n",
    "data['paper'].title = ['Attention is all you need','BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding']\n",
    "data['paper'].comment = ['comment1', 'comment2'] # comment without the page and figure numbers\n",
    "\n",
    "data['author'].num_nodes = 3\n",
    "data['author'].name = ['Ashish Vaswani', 'Noam Shazeer', 'Niki Parmar']\n",
    "\n",
    "data['category'].num_nodes = 4\n",
    "data['journal'].num_nodes = 4\n",
    "data['word'].num_nodes = 5\n",
    "data['word'].name = ['attention', 'transformer', 'language', 'understanding', 'pre-training']\n",
    "data['journal'].name = ['Journal of Machine Learning Research', 'IEEE Transactions on Pattern Analysis and Machine Intelligence', 'Proceedings of the IEEE', 'arXiv']\n",
    "data['category'].name = ['cs.AI', 'cs.LG', 'cs.CV', 'cs.CL']\n",
    "\n",
    "data['paper', 'written_by', 'author'].edge_index = torch.tensor([[1,4],[3,3]])\n",
    "data['paper', 'has_category','category'].edge_index = torch.tensor([[1,4],[3,3]])\n",
    "data['paper', 'in_journal','journal'].edge_index = torch.tensor([[1,4],[3,3]])\n",
    "data['paper', 'has_word','word'].edge_index = torch.tensor([[1,4],[3,3]])\n",
    "data['paper','has_titleword','word'].edge_index = torch.tensor([[1,4],[3,3]])\n",
    "data['word','cooccurs_with','word'].edge_index = torch.tensor([[1,4],[3,3]])\n",
    "\n",
    "data['paper', 'has_word','word'].edge_attr = torch.tensor([[0.34243],[0.2322]])  # tf-idf weights\n",
    "data['word','cooccurs_with','word'].edge_attr = torch.tensor([[0.34243],[0.2322]])  # pmi weights\n",
    "\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old stuff \n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data['paper'].num_nodes = 300\n",
    "data['author'].num_nodes = 200\n",
    "data['paper', 'written_by', 'author'].edge_index = torch.tensor([\n",
    "    [1,2,2],\n",
    "    [100,102,105]\n",
    "]) \n",
    "\n",
    "1,100\n",
    "2,102\n",
    "data['author'].x = torch.tensor([\n",
    "    [3,4,1],\n",
    "    [1,1,1],\n",
    "    [0,0,0]\n",
    "])\n",
    "\n",
    "\n",
    "data['paper', 'written_by', 'author'].edge_attr = torch.tensor([\n",
    "    [3,4,1],\n",
    "    [1,1,1],\n",
    "    [0,0,0]\n",
    "])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "       T.RemoveIsolatedNodes(),\n",
    "       T.ToUndirected(merge=False), # don't merge reversed edges into the original edge type\n",
    "       T.RemoveDuplicatedEdges(),\n",
    "])\n",
    "data_before = data\n",
    "data = transform(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['paper', 'written_by', 'author'].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
