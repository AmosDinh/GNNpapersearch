{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from weaviate import Client\n",
    "from weaviate.util import generate_uuid5\n",
    "from torch import load\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pickle\n",
    "\n",
    "FOLDER = \"results/results\"\n",
    "NODE_TYPES = [\"paper\", \"author\", \"category\", \"word\", \"journal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_names_to_pickle():\n",
    "    graph = pickle.load(open(\"graph.pkl\", \"rb\"))\n",
    "    \n",
    "    for node in NODE_TYPES:\n",
    "        with open(f\"{node}s.pkl\", \"wb\") as f:\n",
    "            pickle.dump(graph[node].name, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uuid(class_name: str, node_id: str) -> str:\n",
    "    return generate_uuid5((node_id, class_name))\n",
    "\n",
    "\n",
    "def get_weaviate_client(db_url: str = \"http://localhost:8081\") -> Client:\n",
    "    return Client(db_url)\n",
    "\n",
    "\n",
    "def delete_schema(client: Client):\n",
    "    schema = client.schema.get()\n",
    "\n",
    "    # Status READONLY is set when disk is over a certain limit, can bespecified in config\n",
    "    for _class in schema[\"classes\"]:\n",
    "        # need to set status to ready on all shards, so we can delete\n",
    "        client.schema.update_class_shard(\n",
    "            class_name=_class[\"class\"],\n",
    "            status=\"READY\",\n",
    "        )\n",
    "    client.schema.delete_all()\n",
    "\n",
    "\n",
    "def create_schema(client: Client, schema_yaml: str):\n",
    "    with Path(schema_yaml).open() as stream:\n",
    "        schema = yaml.safe_load(stream)\n",
    "\n",
    "    for class_obj in schema[\"classes\"]:\n",
    "        print(class_obj)\n",
    "        client.schema.create_class(class_obj)\n",
    "\n",
    "\n",
    "DATA_OB_DICT = {\n",
    "    \"Paper\": \"title\",\n",
    "    \"Author\": \"name\",\n",
    "    \"Category\": \"name\",\n",
    "    \"Word\": \"word\",\n",
    "    \"Journal\": \"name\",\n",
    "    \"Abstract\": \"abstract\",\n",
    "}\n",
    "\n",
    "\n",
    "def generate_object(class_name, node_id, node_name, node_embedding):\n",
    "    data_object = DATA_OB_DICT[class_name]\n",
    "    return dict(\n",
    "        class_name=class_name,\n",
    "        uuid=generate_uuid(class_name, node_id),\n",
    "        data_object={data_object: node_name, \"type\": class_name},\n",
    "        vector=node_embedding,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_all_nodes(node_type: str, embeddings: dict, names: list) -> list:\n",
    "    return [\n",
    "        [\n",
    "            generate_object(node_type, indice, names[indice], embedding)\n",
    "            for embedding, indice in zip(embeddings, indices)\n",
    "        ]\n",
    "        for embeddings, indices in zip(embeddings[\"embeddings\"], embeddings[\"indices\"])\n",
    "    ]\n",
    "\n",
    "\n",
    "client = get_weaviate_client()\n",
    "client.batch.configure(\n",
    "    batch_size=64,\n",
    "    num_workers=10,\n",
    "    dynamic=True,  # dynamically update the `batch_size` based on import speed)\n",
    ")\n",
    "for node_type in NODE_TYPES:\n",
    "    for counter in range(len(list(Path(FOLDER).glob(f\"embeddings_{node_type}*\")))):\n",
    "        path = f\"{FOLDER}/embeddings_{node_type}_{counter}.pt\"\n",
    "        print(path)\n",
    "        embeddings = load(path)\n",
    "        with open(f\"{node_type}s.pkl\", \"rb\") as f:\n",
    "            names = pickle.load(f)\n",
    "        items = get_all_nodes(node_type.capitalize(), embeddings, names)\n",
    "\n",
    "        with client.batch as batch:\n",
    "            [[batch.add_data_object(**data_object) for data_object in x] for x in items]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
